{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/zynicide/wine-reviews/data\n",
    "\n",
    "wine_df = pd.read_csv('data/wine_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87     16933\n",
       "86     12600\n",
       "91     11359\n",
       "92      9613\n",
       "85      9530\n",
       "93      6489\n",
       "84      6480\n",
       "94      3758\n",
       "83      3025\n",
       "82      1836\n",
       "95      1535\n",
       "81       692\n",
       "96       523\n",
       "80       397\n",
       "97       229\n",
       "98        77\n",
       "99        33\n",
       "100       19\n",
       "Name: points, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['points'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aromas include tropical fruit, broom, brimston...\n",
       "1    This is ripe and fruity, a wine that is smooth...\n",
       "2    Tart and snappy, the flavors of lime flesh and...\n",
       "3    Pineapple rind, lemon pith and orange blossom ...\n",
       "4    Much like the regular bottling from 2012, this...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['description'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![google_search.png](images/google_search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripen...\n",
       "1    This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red be...\n",
       "2    Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity...\n",
       "3    Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of ...\n",
       "4    Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['description'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripen...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red be...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling (Lake Michigan Shore)</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal ...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child Block Pinot Noir (Willamette Valley)</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  \\\n",
       "0     Italy   \n",
       "1  Portugal   \n",
       "2        US   \n",
       "3        US   \n",
       "4        US   \n",
       "\n",
       "                                                                                                               description  \\\n",
       "0  Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripen...   \n",
       "1  This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red be...   \n",
       "2  Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity...   \n",
       "3  Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of ...   \n",
       "4  Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal ...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle  \\\n",
       "0          @kerinokeefe   \n",
       "1            @vossroger   \n",
       "2           @paulgwine    \n",
       "3                   NaN   \n",
       "4           @paulgwine    \n",
       "\n",
       "                                                                                 title  \\\n",
       "0                                                    Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1                                        Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2                                        Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                  St. Julian 2013 Reserve Late Harvest Riesling (Lake Michigan Shore)   \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child Block Pinot Noir (Willamette Valley)   \n",
       "\n",
       "          variety               winery rating  \n",
       "0     White Blend              Nicosia    Low  \n",
       "1  Portuguese Red  Quinta dos Avidagos    Low  \n",
       "2      Pinot Gris            Rainstorm    Low  \n",
       "3        Riesling           St. Julian    Low  \n",
       "4      Pinot Noir         Sweet Cheeks    Low  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Turning words in to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Set up your model, fixing any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase   = True,\n",
    "                             ngram_range = (1,1),\n",
    "                             stop_words  = 'english',\n",
    "                             min_df      = .01,\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Fit your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`model.fit(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(wine_df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inpsect your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Create new data based on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "review_word_counts = vectorizer.transform(wine_df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What words are associated with well-reviewed wines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low     51493\n",
       "High    33635\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Set up your model, fixing any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Fit your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`model.fit(X)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`model.fit(X, Y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(review_word_counts, wine_df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We have coefficients now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.33467081,  -7.24590289,  -7.19142933,  -7.20616256,\n",
       "        -7.38885524,  -8.18761044,  -8.89070795, -11.09798286,\n",
       "        -7.20061213,  -7.24397425,  -6.69237287,  -4.00593826,\n",
       "        -6.70465667,  -7.24397425,  -7.25950854,  -6.263145  ,\n",
       "        -6.67477066,  -6.92639671,  -6.56148092,  -6.14471991,\n",
       "        -6.39337878,  -6.09342661,  -7.16437628,  -4.84345499,\n",
       "        -6.96645929,  -6.27185332,  -7.04067957,  -3.78998822,\n",
       "        -6.93484747,  -6.76128647,  -5.86105745,  -7.28728811,\n",
       "        -6.39585097,  -7.30147274,  -6.26459113,  -5.88949074,\n",
       "        -6.73083916,  -7.12085331,  -8.99606846,  -9.17839002,\n",
       "        -6.77928336,  -4.62605818,  -6.80255446,  -7.28127003,\n",
       "        -6.45534174,  -5.38365017,  -5.85864374,  -4.66095875,\n",
       "        -6.82131674,  -5.29641393,  -6.28284647,  -5.05147071,\n",
       "        -7.33256333,  -7.57162234,  -6.77807344,  -5.25233262,\n",
       "        -6.4614902 ,  -7.22300113,  -7.28127003,  -6.99910314,\n",
       "        -6.93202261,  -6.6704181 ,  -5.11679824,  -6.92639671,\n",
       "        -6.60120809,  -7.02817941,  -6.90970648,  -5.45898136,\n",
       "        -6.25953879,  -6.94337025,  -6.60019543,  -6.97231583,\n",
       "        -6.67368074,  -6.92639671,  -8.24885406,  -5.35585418,\n",
       "        -5.83765061,  -6.17138815,  -4.27578547,  -7.14499242,\n",
       "        -5.76966548,  -6.77084449,  -6.78779405,  -4.92438617,\n",
       "        -6.89600763,  -7.57429971,  -5.50665672,  -6.73894574,\n",
       "        -6.66392457,  -7.36248009,  -6.42855828,  -6.28505968,\n",
       "        -6.03022282,  -6.31276643,  -6.62064605,  -7.24783526,\n",
       "        -6.96063686,  -6.76605406,  -7.01583357,  -7.06133161,\n",
       "        -6.71029049,  -6.71937114,  -5.85479388,  -4.80154344,\n",
       "        -7.04698874,  -5.67423501,  -6.93909978,  -6.87981295,\n",
       "        -5.63530735,  -7.44143879,  -6.60934649,  -6.80007922,\n",
       "        -6.5595354 ,  -6.69793772,  -7.28728811,  -7.23057692,\n",
       "        -7.82255487,  -6.81376954,  -6.74594694,  -5.74741811,\n",
       "        -4.30921589,  -6.14087621,  -7.07425586,  -4.5923347 ,\n",
       "        -6.65319485,  -6.59012486,  -5.8944758 ,  -5.40823784,\n",
       "        -6.27696842,  -7.73382675,  -6.93061316,  -6.48106378,\n",
       "        -7.04698874,  -6.99158996,  -7.37558071,  -7.10061653,\n",
       "        -7.26343012,  -5.86882072,  -5.67865535,  -6.2459526 ,\n",
       "        -3.93059431,  -6.04579856,  -7.30761401,  -6.00367509,\n",
       "        -5.63878427,  -6.97820686,  -3.2928417 ,  -6.26459113,\n",
       "        -6.47747633,  -6.96938327,  -8.22287857,  -6.49372218,\n",
       "        -6.8520884 ,  -7.59598078,  -6.53363467,  -7.02507863,\n",
       "        -6.81251719,  -7.17510984,  -4.62241008,  -6.51023631,\n",
       "        -3.71517988,  -6.61755166,  -5.08005344,  -4.95653214,\n",
       "        -7.05015831,  -6.33580892,  -7.05015831,  -7.01583357,\n",
       "        -5.10606387,  -6.59514747,  -6.14664731,  -6.52327188,\n",
       "        -6.65747293,  -4.95888231,  -7.0066732 ,  -6.93626289,\n",
       "        -7.71513462,  -6.31885937,  -6.23114795,  -5.97077739,\n",
       "        -5.341953  ,  -6.24808555,  -6.13069801,  -5.71641117,\n",
       "        -6.0574946 ,  -6.2283527 ,  -6.82384519,  -8.7337042 ,\n",
       "        -7.71205295,  -6.85469596,  -7.23821054,  -6.52514805,\n",
       "        -6.20695044,  -6.99910314,  -5.54467098,  -5.76131929,\n",
       "        -7.86825702,  -7.3516925 ,  -5.98599507,  -7.40910341,\n",
       "        -6.09770404,  -6.30144128,  -5.36670314,  -7.73382675,\n",
       "        -6.37867263,  -4.70226606,  -6.0983166 ,  -5.25602072,\n",
       "        -5.78612127,  -7.55834193,  -5.70146693,  -6.07052025,\n",
       "        -6.74010921,  -7.00212429,  -8.26476952,  -6.94765903,\n",
       "        -7.48706495,  -6.41165171,  -6.702412  ,  -6.84948762,\n",
       "        -6.85339133,  -6.96792021,  -5.44485592,  -5.80559211,\n",
       "        -5.85095879,  -7.36465164,  -6.61344066,  -6.17535117,\n",
       "        -7.07425586,  -6.85339133,  -6.92639671,  -6.90695165,\n",
       "        -7.09396094,  -5.56891459,  -5.8830471 ,  -6.99458846,\n",
       "        -7.02817941,  -6.61652233,  -6.28653788,  -7.16082388,\n",
       "        -6.39998491,  -4.75027528,  -5.67183212,  -4.66518893,\n",
       "        -4.6986319 ,  -6.2459526 ,  -6.85469596,  -5.05297755,\n",
       "        -7.28327204,  -7.25365487,  -7.0036383 ,  -5.93631864,\n",
       "        -8.6675644 ,  -5.76526407,  -6.78657379,  -7.55570688,\n",
       "        -6.25953879,  -3.97101903,  -5.3208936 ,  -5.51825303,\n",
       "        -7.03597368,  -5.50665672,  -6.63626323,  -6.70690639,\n",
       "        -7.36465164,  -7.05015831,  -6.01432243,  -6.79884388,\n",
       "        -5.62380415,  -6.54794106,  -6.37059504,  -4.88046989,\n",
       "        -7.05972776,  -7.64080621,  -7.79878465,  -8.18761044,\n",
       "        -7.66987803,  -7.75287494,  -6.19203491,  -6.60019543,\n",
       "        -7.53229879,  -7.87547727,  -7.83988632,  -6.87847515,\n",
       "        -7.48706495,  -7.86825702,  -6.84689358,  -6.3196236 ,\n",
       "        -6.97673084,  -7.26934146,  -5.31303942,  -6.78779405,\n",
       "        -5.67543862,  -4.40533532,  -6.20695044,  -5.30082044,\n",
       "        -6.4676767 ,  -6.84689358,  -6.93768033,  -4.53233384,\n",
       "        -7.40005357,  -6.50194516,  -7.27927203,  -6.48827752,\n",
       "        -6.19608077,  -6.6682489 ,  -6.61755166,  -7.35815108,\n",
       "        -6.83146911,  -5.62724124,  -6.37220535,  -6.47301005,\n",
       "        -7.69375976,  -7.36900895,  -6.39255607,  -6.55468808,\n",
       "        -6.56538337,  -5.28439522,  -6.81502345,  -5.348011  ,\n",
       "        -7.64367565,  -6.95629218,  -5.53940133,  -6.67586177,\n",
       "        -6.82511181,  -6.22974935,  -5.86009127,  -4.62115037,\n",
       "        -6.34989366,  -6.71595622,  -6.83530298,  -6.27185332,\n",
       "        -4.84170949,  -6.91246891,  -5.67183212,  -6.32115382,\n",
       "        -6.53933269,  -6.05573145,  -6.54794106,  -5.97239682,\n",
       "        -6.8430151 ,  -5.68755508,  -6.96354384,  -6.63941615,\n",
       "        -7.56098394,  -4.6830347 ,  -6.39915675,  -6.01883966,\n",
       "        -6.88249391,  -6.31428619,  -5.67183212,  -7.0051546 ,\n",
       "        -4.37644764,  -5.58382124,  -6.64046933,  -5.76000781,\n",
       "        -7.25755351,  -5.23641994,  -6.92080229,  -6.11437624,\n",
       "        -8.05779882,  -6.68243353,  -5.98818805,  -6.60628682,\n",
       "        -6.76844641,  -6.37301147,  -6.80255446,  -6.51023631,\n",
       "        -5.30496925,  -7.25171123,  -6.0307954 ,  -7.30556273,\n",
       "        -5.15566081,  -7.01583357,  -7.00819411,  -8.2973811 ,\n",
       "        -7.43209292,  -7.15024177,  -7.79209566,  -6.78292193,\n",
       "        -7.62376034,  -6.55759365,  -7.55570688,  -6.50194516,\n",
       "        -6.60934649,  -6.37705188,  -7.27727801,  -6.94765903,\n",
       "        -5.01659451,  -6.52420953,  -3.2604285 ,  -7.35384073,\n",
       "        -6.92499517,  -5.85383373,  -7.07263117,  -6.63836407,\n",
       "        -6.35147095,  -6.36098728,  -6.58214078,  -6.49645566])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "coeficients = pd.Series(nb_classifier.coef_[0],\n",
    "                        index = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022          -11.097983\n",
       "beautifully    -9.178390\n",
       "beautiful      -8.996068\n",
       "2020           -8.890708\n",
       "impressive     -8.733704\n",
       "opulent        -8.667564\n",
       "velvety        -8.297381\n",
       "lovely         -8.264770\n",
       "cellar         -8.248854\n",
       "focused        -8.222879\n",
       "potential      -8.187610\n",
       "2019           -8.187610\n",
       "tightly        -8.057799\n",
       "producer       -7.875477\n",
       "layered        -7.868257\n",
       "purple         -7.868257\n",
       "provide        -7.839886\n",
       "develop        -7.822555\n",
       "polished       -7.798785\n",
       "vines          -7.792096\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeficients.sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "<p> Construct a model of UN speeches to distinquish between those before and after the collapse of the Soviet Union.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Create new data based on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low', 'High', 'Low', ..., 'Low', 'High', 'High'], dtype='<U4')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.predict(review_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "wine_df['prediction']  = nb_classifier.predict(review_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>26996</td>\n",
       "      <td>6639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>7884</td>\n",
       "      <td>43609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction   High    Low\n",
       "rating                  \n",
       "High        26996   6639\n",
       "Low          7884  43609"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(wine_df['rating'], wine_df['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293980828869467"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(wine_df['rating'], wine_df['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115622d68>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(wine_df['rating'], wine_df['prediction'])\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.77      0.80      0.79     33635\n",
      "         Low       0.87      0.85      0.86     51493\n",
      "\n",
      "    accuracy                           0.83     85128\n",
      "   macro avg       0.82      0.82      0.82     85128\n",
      "weighted avg       0.83      0.83      0.83     85128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(wine_df['rating'], wine_df['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Precision: % of selected items that are correct \n",
    "\n",
    "Recall: % of correct items that are selected\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "<p> How's your Kickstarter model doing? How many correct? Is it balanced?</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05837039, 0.94162961],\n",
       "       [0.8189896 , 0.1810104 ],\n",
       "       [0.0073304 , 0.9926696 ],\n",
       "       ...,\n",
       "       [0.31987064, 0.68012936],\n",
       "       [0.92064944, 0.07935056],\n",
       "       [0.65113375, 0.34886625]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.predict_proba(review_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame(nb_classifier.predict_proba(review_word_counts), \n",
    "                          columns=nb_classifier.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058370</td>\n",
       "      <td>0.941630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818990</td>\n",
       "      <td>0.181010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.992670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.990035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.982221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       High       Low\n",
       "0  0.058370  0.941630\n",
       "1  0.818990  0.181010\n",
       "2  0.007330  0.992670\n",
       "3  0.009965  0.990035\n",
       "4  0.017779  0.982221"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wine_df_prediction = pd.concat([wine_df, predict_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'High' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d718942d75b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwine_df_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4718\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4719\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1723\u001b[0m                              .format(key=key,\n\u001b[1;32m   1724\u001b[0m                                      \u001b[0mlabel_axis_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_axis_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m                                      multi_message=multi_message))\n\u001b[0m\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The column label 'High' is not unique."
     ]
    }
   ],
   "source": [
    "wine_df_prediction.sort_values('High', ascending=False)[['description','points']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'Low' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-fa0dd55011f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwine_df_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position)\u001b[0m\n\u001b[1;32m   4717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4718\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4719\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1723\u001b[0m                              .format(key=key,\n\u001b[1;32m   1724\u001b[0m                                      \u001b[0mlabel_axis_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_axis_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1725\u001b[0;31m                                      multi_message=multi_message))\n\u001b[0m\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The column label 'Low' is not unique."
     ]
    }
   ],
   "source": [
    "wine_df_prediction.sort_values('Low', ascending=False)[['description','points']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "  <p> Which <b>post 1989</b> speech had the highest likelihood of being delivered during an earlier period?\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What about overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(wine_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68102"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17026"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase   = True,\n",
    "                             ngram_range = (1,2),\n",
    "                             stop_words  = 'english',\n",
    "                             min_df      = .01,\n",
    "                             max_features = None)\n",
    "\n",
    "vectorizer.fit(train['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(X_train, train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8273618983289771\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train['rating'],\n",
    "                     nb_classifier.predict(X_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "test_wf         = vectorizer.transform(test['description'])\n",
    "test_prediction = nb_classifier.predict(test_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350170327734053\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test['rating'], test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             ngram_range = (1,3),\n",
    "                             stop_words = 'english',\n",
    "                             max_df = .60,\n",
    "                             min_df = 5,\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train['description'])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "X_train = vectorizer.transform(train['description'])\n",
    "nb_classifier.fit(X_train, train['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9169040556811842\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train['rating'],\n",
    "                     nb_classifier.predict(X_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8901679783859979\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(test['rating'],\n",
    "                     nb_classifier.predict(vectorizer.transform(test['description']))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "<p> What happens to your model if you change some of the parameters for your vectorizer? Be sure to spit the data between train and test!\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What about a different model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ln_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nealcaren/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             ngram_range = (1,2),\n",
    "                             stop_words = 'english',\n",
    "                             min_df = .01,\n",
    "                             max_features = None)\n",
    "\n",
    "vectorizer.fit(train['description'])\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "ln_classifier.fit(vectorizer.transform(train['description']), train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8833220757099645\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train['rating'],\n",
    "                     ln_classifier.predict(vectorizer.transform(train['description']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8830024668154587\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test['rating'],\n",
    "                     ln_classifier.predict(vectorizer.transform(test['description']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a22407be0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction = ln_classifier.predict(vectorizer.transform(test['description']))\n",
    "\n",
    "cm = confusion_matrix(test['rating'], test_prediction)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "What is the out sample accuracy of a logistic regression model on your data?\n",
    "<p><code> from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What about a different model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/knn1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf_vector  = TfidfVectorizer(lowercase  =  True,\n",
    "                             ngram_range = (1,2),\n",
    "                             stop_words  = 'english',\n",
    "                             max_df      = .60,\n",
    "                             min_df      = .05,\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(wine_df, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.6, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vector.fit(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "review_tf = tf_vector.transform(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.fit(review_tf, train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_prediction = knn_classifier.predict(review_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431748766543974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(train['rating'], knn_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.84      0.74      0.79      9987\n",
      "         Low       0.85      0.91      0.88     15551\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25538\n",
      "   macro avg       0.84      0.83      0.83     25538\n",
      "weighted avg       0.84      0.84      0.84     25538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train['rating'], knn_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1270d0470>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(train['rating'], knn_prediction)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "<p> What does a k-nearest neigbhor for your speech dataset look like? (Don't forget to shrink your dataframe). How does the accuracy compare?\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/knn2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But what's the best fitting model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# old model: knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "parameters = {'n_neighbors' : [2,3, 7],\n",
    "              'weights'      : ['distance', 'uniform']}\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(KNeighborsClassifier(), \n",
    "                    parameters, \n",
    "                    cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/cv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But what's the best fitting model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('vectorizer' , CountVectorizer()),\n",
    "                     ('classifier' , LogisticRegression())\n",
    "                    ])\n",
    "\n",
    "parameters = {'vectorizer__max_features' : [300, 500, 700],\n",
    "               }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   52.7s finished\n",
      "/Users/nealcaren/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=No...\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_features': [300, 500, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(wine_df['description'],\n",
    "                wine_df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8988934310685086"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=700, min_df=1, ngram_range=(1, 1),\n",
       "                                 preprocessor=None, stop_words=None,\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=700, min_df=1, ngram_range=(1, 1),\n",
       "                                 preprocessor=None, stop_words=None,\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Homework</h3>\n",
    "<p> The \"data\" folder contains board games descriptions scraped from BoardGameGeeks.com. Analyze the relationship between the words in the <code>description</code> and whether or not reviewers thought it was a <code>quality_game</code>. \n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
