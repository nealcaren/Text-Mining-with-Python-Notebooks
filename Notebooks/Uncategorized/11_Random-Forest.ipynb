{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciscion Trees and Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bg_df = pd.read_csv('data/boardgames.csv')\n",
    "\n",
    "bg_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 3) #  Split the sample only three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_names = ['max_players', 'min_players', 'min_playtime', 'max_playtime', 'min_age']\n",
    "\n",
    "dtc.fit(bg_df[x_names], bg_df['quality_game'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_tree(dtc, feature_names = x_names, fontsize = 10, filled =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(export_text(dtc, feature_names = x_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth =3 )\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rf.fit(bg_df[x_names], bg_df['quality_game'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rf.estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(rf.estimators_[5], feature_names = x_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plot_tree(rf.estimators_[-2], \n",
    "          feature_names = x_names, fontsize = 10, filled =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "imp = pd.DataFrame(rf.feature_importances_, index = x_names)\n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your Turn</h3>\n",
    "<p> Run the model again chaning the max_depth parameter. What does it mean to change this parameter? How do the results vary?\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your Turn</h3>\n",
    "<p> Find the documentation for this function. What other parameters are available? Add one to your model.\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your Turn</h3>\n",
    "<p> Produce predicted values from your model and evaluate the accuracy score.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to supersize things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['category_cardgame',\n",
    "       'category_wargame', 'category_fantasy', 'category_dice',\n",
    "       'category_partygame', 'category_fighting', 'category_sciencefiction',\n",
    "       'category_abstractstrategy', 'category_economic',\n",
    "       'category_childrensgame', 'category_worldwarii', 'category_bluffing',\n",
    "       'category_animals', 'category_humor', 'category_actiondexterity',\n",
    "       'category_adventure', 'category_moviestvradiotheme',\n",
    "       'category_medieval', 'category_deduction', 'category_miniatures']\n",
    "\n",
    "mechanics = ['mechanic_dicerolling', 'mechanic_handmanagement',\n",
    "       'mechanic_hexandcounter', 'mechanic_setcollection',\n",
    "       'mechanic_variableplayerpowers', 'mechanic_none',\n",
    "       'mechanic_tileplacement', 'mechanic_modularboard',\n",
    "       'mechanic_carddrafting', 'mechanic_rollspinandmove',\n",
    "       'mechanic_areacontrolareainfluence', 'mechanic_auctionbidding',\n",
    "       'mechanic_simulation', 'mechanic_areamovement',\n",
    "       'mechanic_simultaneousactionselection',\n",
    "       'mechanic_actionpointallowancesystem', 'mechanic_cooperativeplay',\n",
    "       'mechanic_pointtopointmovement', 'mechanic_partnerships',\n",
    "       'mechanic_memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = ['complexity', 'max_players', 'min_players', 'min_playtime', 'max_playtime', 'min_age'] \n",
    "many_xs = x_names + mechanics + categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "param_dist = {\"max_features\": [4, 7],\n",
    "              \"min_samples_split\": [10],\n",
    "              \"n_estimators\" : [100, 200]}\n",
    "\n",
    "\n",
    "rfgs = GridSearchCV( RandomForestClassifier(),\n",
    "                    param_dist,\n",
    "                    cv = 5,\n",
    "                    n_jobs = -1,\n",
    "                    verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rfgs.fit(bg_df[many_xs], bg_df['quality_game'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rfgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rf_best = rfgs.best_estimator_\n",
    "pd.DataFrame(rf_best.feature_importances_, index = many_xs).sort_values(by = 0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(export_text(rf_best.estimators_[11], feature_names = many_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Your Turn</h3>\n",
    "<p> Work with your group to find a best fitting model. Compare the accuracy with of logistic regression.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3> Bonus Challenge</h3>\n",
    "\n",
    "<p> Bonus challenge: Use both features in the data set and ones you construct from a topic model!\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
