{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Beyond LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling's ability to pick up on latent themes in large collections of texts can be quite useful (hence the model's popularity), LDA models nevertheless have a number of limitations. To name a few, LDA models don't account for the passage of time, the models have difficulty determining any relationships among generated topics, and topics become considerably less useful when the model is applied to shorter corpera with shorter document lengths.\n",
    "\n",
    "In this chapter, we'll present some alternative approaches to topic modeling that help to mitigate these limitations of LDA modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Topic Modeling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing Dynamic Topic Modeling, or DTM, [Blei and Lafferty](https://dl.acm.org/doi/pdf/10.1145/1143844.1143859) wanted to account for the possibility that content within a collection of texts could evolve over time, something traditional LDA topic modeling doesn't consider. To do so, they developed a form of topic modeling that could trace the evolution of the topics generated over time. In DTM, then, we can see our topics develop as time passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "\n",
    "In order to run Dynamic Topic Modeling in Python, we'll be installing the [Gensim](https://radimrehurek.com/gensim/index.html) topic modeling library. (We'll also want to make sure we've installed Gensim's dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Gensim, we'll import [ldaseq](https://radimrehurek.com/gensim/models/ldaseqmodel.html), the library's built-in Dynamic Topic Modeling function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaSeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some relavant parameters for `LdaSeqModel` are listed below. For an exhaustive list of parameters, see [here](https://radimrehurek.com/gensim/models/ldaseqmodel.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LdaSeqModel Parameters: \n",
    "\n",
    "- **corpus**: \n",
    "\n",
    "\n",
    "- **id2word**: Allows us to map word IDs onto words. Helps with determining the size of our vocabulary.\n",
    "\n",
    "\n",
    "- **time_slice**:\n",
    "\n",
    "\n",
    "- **num_topics**:\n",
    "\n",
    "\n",
    "- **chunksize**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get a handle on the `LdaSeqModel` function, we'll run the model with gensim's common corpus and dictionary. We'll use the common dictionary to for the `id2word` parameter when we run our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.test.utils import common_dictionary\n",
    "\n",
    "corpus = common_corpus\n",
    "dictionary = common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tmwp/lib/python3.8/site-packages/gensim/models/ldaseqmodel.py:293: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "ldaseq = LdaSeqModel(corpus=common_corpus, id2word=dictionary, time_slice=[2, 4, 3], num_topics=2, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('graph', 0.24397931991219668),\n",
       "  ('minors', 0.24397931991219668),\n",
       "  ('human', 0.09001845665111263),\n",
       "  ('interface', 0.09001845665111263),\n",
       "  ('survey', 0.09001845665111263),\n",
       "  ('computer', 0.05535520920529867),\n",
       "  ('response', 0.03110513016949502),\n",
       "  ('system', 0.03110513016949502),\n",
       "  ('time', 0.03110513016949502),\n",
       "  ('user', 0.03110513016949502),\n",
       "  ('eps', 0.03110513016949502),\n",
       "  ('trees', 0.03110513016949502)],\n",
       " [('system', 0.212521467190357),\n",
       "  ('user', 0.16521007402047225),\n",
       "  ('trees', 0.11814820948685073),\n",
       "  ('response', 0.06745061829382003),\n",
       "  ('time', 0.06745061829382003),\n",
       "  ('eps', 0.06745061829382003),\n",
       "  ('graph', 0.06745061829382003),\n",
       "  ('human', 0.050716353804357746),\n",
       "  ('interface', 0.050716353804357746),\n",
       "  ('survey', 0.050716353804357746),\n",
       "  ('minors', 0.050716353804357746),\n",
       "  ('computer', 0.031452360909608915)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('graph', 0.24452847533931363),\n",
       "  ('minors', 0.24452847533931363),\n",
       "  ('human', 0.08985079871146644),\n",
       "  ('interface', 0.08985079871146644),\n",
       "  ('survey', 0.08985079871146644),\n",
       "  ('computer', 0.05523817104959015),\n",
       "  ('response', 0.031025413689563866),\n",
       "  ('system', 0.031025413689563866),\n",
       "  ('time', 0.031025413689563866),\n",
       "  ('user', 0.031025413689563866),\n",
       "  ('eps', 0.031025413689563866),\n",
       "  ('trees', 0.031025413689563866)],\n",
       " [('system', 0.21255385122072792),\n",
       "  ('user', 0.16484640415976715),\n",
       "  ('trees', 0.11872939728000363),\n",
       "  ('response', 0.06742129842200774),\n",
       "  ('time', 0.06742129842200774),\n",
       "  ('eps', 0.06742129842200774),\n",
       "  ('graph', 0.06742129842200774),\n",
       "  ('human', 0.05068476120535119),\n",
       "  ('interface', 0.05068476120535119),\n",
       "  ('survey', 0.05068476120535119),\n",
       "  ('minors', 0.05068476120535119),\n",
       "  ('computer', 0.03144610883006575)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('graph', 0.2450045719364962),\n",
       "  ('minors', 0.2450045719364962),\n",
       "  ('human', 0.08970051065008355),\n",
       "  ('interface', 0.08970051065008355),\n",
       "  ('survey', 0.08970051065008355),\n",
       "  ('computer', 0.05511309118233615),\n",
       "  ('response', 0.030962705499070146),\n",
       "  ('system', 0.030962705499070146),\n",
       "  ('time', 0.030962705499070146),\n",
       "  ('user', 0.030962705499070146),\n",
       "  ('eps', 0.030962705499070146),\n",
       "  ('trees', 0.030962705499070146)],\n",
       " [('system', 0.2125540016819885),\n",
       "  ('user', 0.1649510553212659),\n",
       "  ('trees', 0.11875577524080093),\n",
       "  ('response', 0.06740263821463657),\n",
       "  ('time', 0.06740263821463657),\n",
       "  ('eps', 0.06740263821463657),\n",
       "  ('graph', 0.06740263821463657),\n",
       "  ('human', 0.05066598546277992),\n",
       "  ('interface', 0.05066598546277992),\n",
       "  ('survey', 0.05066598546277992),\n",
       "  ('minors', 0.05066598546277992),\n",
       "  ('computer', 0.03146467304627889)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import DtmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dictionary = Dictionary.load('news_dictionary')\n",
    "except FileNotFoundError as e:\n",
    "    raise ValueError(\"SKIP: Please download the Corpus/news_dictionary dataset.\")\n",
    "corpus = bleicorpus.BleiCorpus('news_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = [438, 430, 456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Text Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling works well when the texts in our corpus are considerably lengthy (around fifty words or more), LDA models run into some issues when applied to shorter texts. This happens because of a major assumption of LDA modeling: that each text is a *mixture of topics*. While this makes sense in the case of longer texts, shorter texts, like social media posts, often consist of only a *single topic*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on it...Code's giving me trouble but that's nothing new. \n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import gsdmm\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['talk.politics.mideast', 'comp.windows.x', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "newsgroups_train_subject = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data_subject = newsgroups_train_subject.data\n",
    "\n",
    "targets = newsgroups_train.target.tolist()\n",
    "target_names = newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    593\n",
       "0    593\n",
       "2    564\n",
       "Name: targets, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if our topics are evenly distributed\n",
    "df_targets = pd.DataFrame({'targets': targets})\n",
    "order_list = df_targets.targets.value_counts()\n",
    "order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_sentence(data_subject):\n",
    "    list_first_sentence = []\n",
    "    for text in data:\n",
    "        first_sentence = text.split(\".\")[0].replace(\"\\n\", \"\")\n",
    "        list_first_sentence.append(first_sentence)\n",
    "    return list_first_sentence\n",
    "\n",
    "\n",
    "def extract_subject(data):\n",
    "    c = 0\n",
    "    s = \"Subject:\"\n",
    "    list_subjects = []\n",
    "    for new in data_subject:    \n",
    "        lines = new.split(\"\\n\")\n",
    "        b = 0 # loop out at the first \"Subject:\", they may be several and we want first one only\n",
    "        for line in lines:\n",
    "            if s in line and b == 0:\n",
    "                subject = \" \".join(line.split(\":\")[1:]).strip()\n",
    "                subject = subject.replace('Re', '').strip()\n",
    "                list_subjects.append(subject)\n",
    "                c += 1\n",
    "                b = 1\n",
    "    return list_subjects\n",
    "   \n",
    "    \n",
    "def concatenate(list_first_sentence, list_subjects):\n",
    "    list_docs = []\n",
    "    for i in range(len(list_first_sentence)):\n",
    "        list_docs.append(list_subjects[i] + \" \" + list_first_sentence[i])\n",
    "    return list_docs\n",
    "\n",
    "\n",
    "list_first_sentence = extract_first_sentence(data)\n",
    "list_subjects = extract_subject(data_subject)\n",
    "list_docs = concatenate(list_first_sentence, list_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_true_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevator to the top floor Reading from a Amoco...</td>\n",
       "      <td>1</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Title for XTerm Yet again,the escape sequences...</td>\n",
       "      <td>0</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Israeli press. Madness. Before getting ex...</td>\n",
       "      <td>2</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accounts of Anti-Armenian Human Right Violatio...</td>\n",
       "      <td>2</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many israeli soldiers does it take to kill...</td>\n",
       "      <td>2</td>\n",
       "      <td>mideast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  topic_id topic_true_name\n",
       "0  Elevator to the top floor Reading from a Amoco...         1           space\n",
       "1  Title for XTerm Yet again,the escape sequences...         0               x\n",
       "2  From Israeli press. Madness. Before getting ex...         2         mideast\n",
       "3  Accounts of Anti-Armenian Human Right Violatio...         2         mideast\n",
       "4  How many israeli soldiers does it take to kill...         2         mideast"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['content', 'topic_id', 'topic_true_name'])\n",
    "df['content'] = list_docs\n",
    "df['topic_id'] = targets\n",
    "\n",
    "def true_topic_name(x, target_names):\n",
    "    return target_names[x].split('.')[-1]\n",
    "\n",
    "df['topic_true_name'] = df['topic_id'].apply(lambda x: true_topic_name(x, target_names))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization & Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(str(df['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUNCT \t 0\n",
      "SPACE \t       \n",
      "NOUN \t Elevator\n",
      "ADP \t to\n",
      "DET \t the\n",
      "ADJ \t top\n",
      "NOUN \t floor\n",
      "VERB \t Reading\n",
      "ADP \t from\n",
      "DET \t a\n",
      "PROPN \t Amoco\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 1\n",
      "SPACE \t       \n",
      "NOUN \t Title\n",
      "ADP \t for\n",
      "PROPN \t XTerm\n",
      "ADV \t Yet\n",
      "ADV \t again\n",
      "PUNCT \t ,\n",
      "DET \t the\n",
      "NOUN \t escape\n",
      "NOUN \t sequences\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 2\n",
      "SPACE \t       \n",
      "ADP \t From\n",
      "ADJ \t Israeli\n",
      "NOUN \t press\n",
      "PUNCT \t .\n",
      "NOUN \t Madness\n",
      "PUNCT \t .\n",
      "ADP \t Before\n",
      "VERB \t getting\n",
      "NOUN \t ex\n",
      "PROPN \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 3\n",
      "SPACE \t       \n",
      "NOUN \t Accounts\n",
      "ADP \t of\n",
      "ADJ \t Anti\n",
      "ADJ \t -\n",
      "ADJ \t Armenian\n",
      "PROPN \t Human\n",
      "NOUN \t Right\n",
      "PROPN \t Violatio\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 4\n",
      "SPACE \t       \n",
      "ADV \t How\n",
      "ADJ \t many\n",
      "ADJ \t israeli\n",
      "NOUN \t soldiers\n",
      "AUX \t does\n",
      "PRON \t it\n",
      "VERB \t take\n",
      "PART \t to\n",
      "VERB \t kill\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "                              \n",
      "PUNCT \t ...\n",
      "SPACE \t                        \n",
      "\n",
      "NUM \t 1745\n",
      "SPACE \t    \n",
      "PROPN \t Atlas\n",
      "VERB \t revisited\n",
      "SPACE \t   \n",
      "PRON \t I\n",
      "VERB \t found\n",
      "PRON \t it\n",
      "ADV \t very\n",
      "ADJ \t interesting\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 1746\n",
      "SPACE \t       \n",
      "ADV \t How\n",
      "PART \t to\n",
      "AUX \t get\n",
      "NOUN \t 24bit\n",
      "NOUN \t color\n",
      "ADP \t with\n",
      "PROPN \t xview\n",
      "NOUN \t frames\n",
      "PUNCT \t ?\n",
      "INTJ \t Yes\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 1747\n",
      "SPACE \t    \n",
      "PROPN \t Deir\n",
      "PROPN \t Yassin\n",
      "PRON \t You\n",
      "ADV \t apparently\n",
      "VERB \t think\n",
      "PRON \t you\n",
      "AUX \t are\n",
      "DET \t some\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 1748\n",
      "SPACE \t    \n",
      "PROPN \t Vulcan\n",
      "PUNCT \t ?\n",
      "SPACE \t  \n",
      "PUNCT \t (\n",
      "INTJ \t No\n",
      "PUNCT \t ,\n",
      "PART \t not\n",
      "DET \t the\n",
      "NOUN \t guy\n",
      "ADP \t with\n",
      "DET \t the\n",
      "NOUN \t ears\n",
      "PUNCT \t !\n",
      "PUNCT \t )\n",
      "DET \t The\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NUM \t 1749\n",
      "SPACE \t    \n",
      "PROPN \t REPOST\n",
      "SPACE \t  \n",
      "PROPN \t XView\n",
      "NOUN \t slider\n",
      "INTJ \t Hi\n",
      "PROPN \t Xperts\n",
      "PUNCT \t ,\n",
      "DET \t this\n",
      "AUX \t is\n",
      "DET \t a\n",
      "NOUN \t repos\n",
      "PUNCT \t ...\n",
      "SPACE \t \n",
      "\n",
      "NOUN \t Name\n",
      "PUNCT \t :\n",
      "NOUN \t content\n",
      "PUNCT \t ,\n",
      "NOUN \t Length\n",
      "PUNCT \t :\n",
      "NUM \t 1750\n",
      "PUNCT \t ,\n",
      "PROPN \t dtype\n",
      "PUNCT \t :\n",
      "NOUN \t object\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.pos_, '\\t', token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Alghamdi, Rubayyi and Khalid Alfalqi. 2015. \"A Survey of Topic Modeling in Text Mining.\" *Int. J. Adv. Comput. Sci. Appl.(IJACSA)*, 6(1).\n",
    "\n",
    "Blei, David M. and John D. Lafferty. 2006. \"Dynamic Topic Models.\" In *Proceedings of the 23rd International Conference on Machine Learning* (pp. 113-120).\n",
    "\n",
    "https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883\n",
    "\n",
    "https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
