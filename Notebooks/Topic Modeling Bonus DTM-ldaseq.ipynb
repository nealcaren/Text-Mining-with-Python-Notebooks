{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Beyond LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling's ability to pick up on latent themes in large collections of texts can be quite useful (hence the model's popularity), LDA models nevertheless have a number of limitations. To name a few, LDA models don't account for the passage of time, the models have difficulty determining any relationships among generated topics, and topics become considerably less useful when the model is applied to shorter corpera with shorter document lengths.\n",
    "\n",
    "In this chapter, we'll present some alternative approaches to topic modeling that help to mitigate these limitations of LDA modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Topic Modeling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing Dynamic Topic Modeling, or DTM, [Blei and Lafferty](https://dl.acm.org/doi/pdf/10.1145/1143844.1143859) wanted to account for the possibility that content within a collection of texts could evolve over time, something traditional LDA topic modeling doesn't consider. To do so, they developed a form of topic modeling that could trace the evolution of the topics generated over time. In DTM, then, we can see our topics develop as time passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "\n",
    "In order to run Dynamic Topic Modeling in Python, we'll be installing the [Gensim](https://radimrehurek.com/gensim/index.html) topic modeling library. (We'll also want to make sure we've installed Gensim's dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Gensim, we'll import [ldaseq](https://radimrehurek.com/gensim/models/ldaseqmodel.html), the library's built-in Dynamic Topic Modeling function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaSeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some relavant parameters for `LdaSeqModel` are listed below. For an exhaustive list of parameters, see [here](https://radimrehurek.com/gensim/models/ldaseqmodel.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LdaSeqModel Parameters: \n",
    "\n",
    "- **corpus**: The collection of document vectors we'll use to fit our LDA Sequence model.\n",
    "\n",
    "\n",
    "- **id2word**: Allows us to map word IDs onto words, and helps determinine the size of our vocabulary.\n",
    "\n",
    "\n",
    "- **time_slice**: The number of documents we'd like to include within each period of time we want our model to consider. \n",
    "\n",
    "\n",
    "- **num_topics**: The total number of topics we'd like our model to determine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get a handle on the `LdaSeqModel` function, we'll run the model with gensim's common corpus and dictionary. We'll use the common dictionary for the `id2word` parameter when we run our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.test.utils import common_dictionary\n",
    "\n",
    "corpus = common_corpus\n",
    "dictionary = common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "ldaseq = LdaSeqModel(corpus=common_corpus, id2word=dictionary, time_slice=[2, 4, 3], num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, the topics generated with the Gensim common corpus and dictionary don't appear to vary much over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21157474442727292),\n",
       "  ('user', 0.16464543889319655),\n",
       "  ('computer', 0.11780520871853883),\n",
       "  ('interface', 0.11780520871853883),\n",
       "  ('eps', 0.06967385482884698),\n",
       "  ('response', 0.06951097868862414),\n",
       "  ('time', 0.06951097868862414),\n",
       "  ('survey', 0.051180555909905195),\n",
       "  ('trees', 0.032452567340626),\n",
       "  ('graph', 0.032452567340626),\n",
       "  ('minors', 0.032452567340626),\n",
       "  ('human', 0.030935329104574284)],\n",
       " [('trees', 0.32492222725659636),\n",
       "  ('graph', 0.3235563263440136),\n",
       "  ('minors', 0.2205714063302323),\n",
       "  ('computer', 0.0382488601600507),\n",
       "  ('survey', 0.022503013800186142),\n",
       "  ('human', 0.0100605551936047),\n",
       "  ('interface', 0.0100605551936047),\n",
       "  ('response', 0.0100605551936047),\n",
       "  ('time', 0.0100605551936047),\n",
       "  ('user', 0.0100605551936047),\n",
       "  ('system', 0.00994769507044868),\n",
       "  ('eps', 0.00994769507044868)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21240589151067885),\n",
       "  ('user', 0.1646899189988433),\n",
       "  ('computer', 0.11749357289440712),\n",
       "  ('interface', 0.11749357289440712),\n",
       "  ('eps', 0.06963604929122659),\n",
       "  ('response', 0.0694731541329969),\n",
       "  ('time', 0.0694731541329969),\n",
       "  ('survey', 0.05114236405938337),\n",
       "  ('trees', 0.03241859405373477),\n",
       "  ('graph', 0.03241859405373477),\n",
       "  ('minors', 0.03241859405373477),\n",
       "  ('human', 0.030936539923855384)],\n",
       " [('trees', 0.3249256535151684),\n",
       "  ('graph', 0.32373545741107845),\n",
       "  ('minors', 0.22060806640237762),\n",
       "  ('computer', 0.03819443709873786),\n",
       "  ('survey', 0.022472092171356966),\n",
       "  ('human', 0.010041390232247207),\n",
       "  ('interface', 0.010041390232247207),\n",
       "  ('response', 0.010041390232247207),\n",
       "  ('time', 0.010041390232247207),\n",
       "  ('user', 0.010041390232247207),\n",
       "  ('system', 0.00992867112002237),\n",
       "  ('eps', 0.00992867112002237)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21241936929164823),\n",
       "  ('user', 0.16472754916179352),\n",
       "  ('computer', 0.11755004609140896),\n",
       "  ('interface', 0.11755004609140896),\n",
       "  ('eps', 0.06960644191233825),\n",
       "  ('response', 0.06944356260480058),\n",
       "  ('time', 0.06944356260480058),\n",
       "  ('survey', 0.05111543816120229),\n",
       "  ('trees', 0.032396675636444675),\n",
       "  ('graph', 0.032396675636444675),\n",
       "  ('minors', 0.032396675636444675),\n",
       "  ('human', 0.030953957171264507)],\n",
       " [('graph', 0.32400816741793875),\n",
       "  ('trees', 0.32379355787054775),\n",
       "  ('minors', 0.22150884150941086),\n",
       "  ('computer', 0.038181772854098815),\n",
       "  ('survey', 0.0224696342220385),\n",
       "  ('human', 0.010037636236713735),\n",
       "  ('interface', 0.010037636236713735),\n",
       "  ('response', 0.010037636236713735),\n",
       "  ('time', 0.010037636236713735),\n",
       "  ('user', 0.010037636236713735),\n",
       "  ('system', 0.009924922471198317),\n",
       "  ('eps', 0.009924922471198317)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's alright: we have no reason to expect any changes! In order to see some real time variance, let's walk through how to apply LDA Sequence topic modeling to our UN general debate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "un_df = pd.read_json('un-general-debates.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = un_df['speech_year'] < 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = un_df['speech_year'] > 1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-0df7f11f4650>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  un_df = un_df[b == False]\n"
     ]
    }
   ],
   "source": [
    "un_df = un_df[a == False]\n",
    "un_df = un_df[b == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     660.000000\n",
       "mean     1991.546970\n",
       "std         1.119251\n",
       "min      1990.000000\n",
       "25%      1991.000000\n",
       "50%      1992.000000\n",
       "75%      1993.000000\n",
       "max      1993.000000\n",
       "Name: speech_year, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df['speech_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Corpus\n",
    "\n",
    "[Corpora and Vector Spaces, Gensim style](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ﻿It is indeed a pleasure for me and the member...\n",
       "1       ﻿\\nMay I begin by congratulating you. Sir, on ...\n",
       "2       ﻿\\nMr. President, it is a particular pleasure ...\n",
       "3       ﻿\\nDuring the debate at the fortieth session o...\n",
       "4       ﻿I should like at the outset to express my del...\n",
       "                              ...                        \n",
       "3209    I should like to congratulate\\nMr. Essy on his...\n",
       "3210    It is with pleasure that I begin this speech b...\n",
       "3211    Allow me first of all, Sir, to congratulate yo...\n",
       "3212    It is a great pleasure to attend the beginning...\n",
       "3213    Your election,\\nSir, to the presidency of the ...\n",
       "Name: speech_text, Length: 991, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df['speech_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = un_df['speech_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "class Corpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in un_df['speech_text']:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Corpus object at 0x113d09610>\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly = Corpus()\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly:  # load one vector into memory at a time\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Our Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(53943 unique tokens: ['(gnp)', '-', '0.15', '0.7', '1980s']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from six import iteritems\n",
    "# collect statistics about all tokens\n",
    "dictionary = corpora.Dictionary(line.lower().split() for line in un_df['speech_text'])\n",
    "# remove stop words and words that appear only once\n",
    "stoplist = set('i me my myself we our ours ourselves you your yours yourself yourselves he him his himself she her hers herself it its itself they them their theirs themselves what which who whom this that these those am is are was were be been being have has had having do does did doing a an the and but if or because as until while of at by for with about against between into through during before after above below to from up down in out on off over under again further then once here there when where why how all any both each few more most other some such no nor not only own same so than too very s t can will just don should now'.split())\n",
    "stop_ids = [\n",
    "    dictionary.token2id[stopword]\n",
    "    for stopword in stoplist\n",
    "    if stopword in dictionary.token2id\n",
    "]\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids) \n",
    "dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Time Slices\n",
    "\n",
    "Let's say we want to look at the evolution of our UN general debate topics over the two years leading up to, and the two years following, the dissolution of the Soviet Union:\n",
    "\n",
    "- 1990-1991 = 156+162 = **318**\n",
    "\n",
    "\n",
    "- 1992-1993 = 167+175 = **342**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = [318,342]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ldaseq = LdaSeqModel(corpus=corpus_memory_friendly, id2word=dictionary, time_slice=time_slice, num_topics=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Text Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling works well when the texts in our corpus are considerably lengthy (around fifty words or more), LDA models run into some issues when applied to shorter texts. This happens because of a major assumption of LDA modeling: that each text is a *mixture of topics*. While this makes sense in the case of longer texts, shorter texts, like social media posts, often consist of only a *single topic*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on it...Code's giving me trouble but that's nothing new. \n",
    "\n",
    "import spacy\n",
    "import gsdmm\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['talk.politics.mideast', 'comp.windows.x', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "newsgroups_train_subject = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data_subject = newsgroups_train_subject.data\n",
    "\n",
    "targets = newsgroups_train.target.tolist()\n",
    "target_names = newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Alghamdi, Rubayyi and Khalid Alfalqi. 2015. \"A Survey of Topic Modeling in Text Mining.\" *Int. J. Adv. Comput. Sci. Appl.(IJACSA)*, 6(1).\n",
    "\n",
    "Blei, David M. and John D. Lafferty. 2006. \"Dynamic Topic Models.\" In *Proceedings of the 23rd International Conference on Machine Learning* (pp. 113-120).\n",
    "\n",
    "https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883\n",
    "\n",
    "https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
