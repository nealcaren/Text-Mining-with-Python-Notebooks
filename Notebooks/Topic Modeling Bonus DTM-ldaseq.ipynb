{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Beyond LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling's ability to pick up on latent themes in large collections of texts can be quite useful (hence the model's popularity), LDA models nevertheless have a number of limitations. To name a few, LDA models don't account for the passage of time, the models have difficulty determining any relationships among generated topics, and topics become considerably less useful when the model is applied to shorter corpera with shorter document lengths.\n",
    "\n",
    "In this chapter, we'll present some alternative approaches to topic modeling that help to mitigate these limitations of LDA modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Topic Modeling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing Dynamic Topic Modeling, or DTM, [Blei and Lafferty](https://dl.acm.org/doi/pdf/10.1145/1143844.1143859) wanted to account for the possibility that content within a collection of texts could evolve over time, something traditional LDA topic modeling doesn't consider. To do so, they developed a form of topic modeling that could trace the evolution of the topics generated over time. In DTM, then, we can see our topics develop as time passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "\n",
    "In order to run Dynamic Topic Modeling in Python, we'll be installing the [Gensim](https://radimrehurek.com/gensim/index.html) topic modeling library. (We'll also want to make sure we've installed Gensim's dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Gensim, we'll import [ldaseq](https://radimrehurek.com/gensim/models/ldaseqmodel.html), the library's built-in Dynamic Topic Modeling function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaSeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some relavant parameters for `LdaSeqModel` are listed below. For an exhaustive list of parameters, see [here](https://radimrehurek.com/gensim/models/ldaseqmodel.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LdaSeqModel Parameters: \n",
    "\n",
    "- **corpus**: \n",
    "\n",
    "\n",
    "- **id2word**: Allows us to map word IDs onto words. Helps with determining the size of our vocabulary.\n",
    "\n",
    "\n",
    "- **time_slice**:\n",
    "\n",
    "\n",
    "- **num_topics**:\n",
    "\n",
    "\n",
    "- **chunksize**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get a handle on the `LdaSeqModel` function, we'll run the model with gensim's common corpus and dictionary. We'll use the common dictionary to for the `id2word` parameter when we run our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.test.utils import common_dictionary\n",
    "\n",
    "corpus = common_corpus\n",
    "dictionary = common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tmwp/lib/python3.8/site-packages/gensim/models/ldaseqmodel.py:293: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "ldaseq = LdaSeqModel(corpus=common_corpus, id2word=dictionary, time_slice=[2, 4, 3], num_topics=2, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('graph', 0.24397931991219668),\n",
       "  ('minors', 0.24397931991219668),\n",
       "  ('human', 0.09001845665111263),\n",
       "  ('interface', 0.09001845665111263),\n",
       "  ('survey', 0.09001845665111263),\n",
       "  ('computer', 0.05535520920529867),\n",
       "  ('response', 0.03110513016949502),\n",
       "  ('system', 0.03110513016949502),\n",
       "  ('time', 0.03110513016949502),\n",
       "  ('user', 0.03110513016949502),\n",
       "  ('eps', 0.03110513016949502),\n",
       "  ('trees', 0.03110513016949502)],\n",
       " [('system', 0.212521467190357),\n",
       "  ('user', 0.16521007402047225),\n",
       "  ('trees', 0.11814820948685073),\n",
       "  ('response', 0.06745061829382003),\n",
       "  ('time', 0.06745061829382003),\n",
       "  ('eps', 0.06745061829382003),\n",
       "  ('graph', 0.06745061829382003),\n",
       "  ('human', 0.050716353804357746),\n",
       "  ('interface', 0.050716353804357746),\n",
       "  ('survey', 0.050716353804357746),\n",
       "  ('minors', 0.050716353804357746),\n",
       "  ('computer', 0.031452360909608915)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('graph', 0.24452847533931363),\n",
       "  ('minors', 0.24452847533931363),\n",
       "  ('human', 0.08985079871146644),\n",
       "  ('interface', 0.08985079871146644),\n",
       "  ('survey', 0.08985079871146644),\n",
       "  ('computer', 0.05523817104959015),\n",
       "  ('response', 0.031025413689563866),\n",
       "  ('system', 0.031025413689563866),\n",
       "  ('time', 0.031025413689563866),\n",
       "  ('user', 0.031025413689563866),\n",
       "  ('eps', 0.031025413689563866),\n",
       "  ('trees', 0.031025413689563866)],\n",
       " [('system', 0.21255385122072792),\n",
       "  ('user', 0.16484640415976715),\n",
       "  ('trees', 0.11872939728000363),\n",
       "  ('response', 0.06742129842200774),\n",
       "  ('time', 0.06742129842200774),\n",
       "  ('eps', 0.06742129842200774),\n",
       "  ('graph', 0.06742129842200774),\n",
       "  ('human', 0.05068476120535119),\n",
       "  ('interface', 0.05068476120535119),\n",
       "  ('survey', 0.05068476120535119),\n",
       "  ('minors', 0.05068476120535119),\n",
       "  ('computer', 0.03144610883006575)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('graph', 0.2450045719364962),\n",
       "  ('minors', 0.2450045719364962),\n",
       "  ('human', 0.08970051065008355),\n",
       "  ('interface', 0.08970051065008355),\n",
       "  ('survey', 0.08970051065008355),\n",
       "  ('computer', 0.05511309118233615),\n",
       "  ('response', 0.030962705499070146),\n",
       "  ('system', 0.030962705499070146),\n",
       "  ('time', 0.030962705499070146),\n",
       "  ('user', 0.030962705499070146),\n",
       "  ('eps', 0.030962705499070146),\n",
       "  ('trees', 0.030962705499070146)],\n",
       " [('system', 0.2125540016819885),\n",
       "  ('user', 0.1649510553212659),\n",
       "  ('trees', 0.11875577524080093),\n",
       "  ('response', 0.06740263821463657),\n",
       "  ('time', 0.06740263821463657),\n",
       "  ('eps', 0.06740263821463657),\n",
       "  ('graph', 0.06740263821463657),\n",
       "  ('human', 0.05066598546277992),\n",
       "  ('interface', 0.05066598546277992),\n",
       "  ('survey', 0.05066598546277992),\n",
       "  ('minors', 0.05066598546277992),\n",
       "  ('computer', 0.03146467304627889)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.wrappers import DtmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dictionary = Dictionary.load('news_dictionary')\n",
    "except FileNotFoundError as e:\n",
    "    raise ValueError(\"SKIP: Please download the Corpus/news_dictionary dataset.\")\n",
    "corpus = bleicorpus.BleiCorpus('news_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = [438, 430, 456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaseq = ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, time_slice=time_slice, num_topics=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Text Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling works well when the texts in our corpus are considerably lengthy (around fifty words or more), LDA models run into some issues when applied to shorter texts. This happens because of a major assumption of LDA modeling: that each text is a *mixture of topics*. While this makes sense in the case of longer texts, shorter texts, like social media posts, often consist of only a *single topic*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on it...Code's giving me trouble but that's nothing new. \n",
    "\n",
    "import spacy\n",
    "import gsdmm\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['talk.politics.mideast', 'comp.windows.x', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "newsgroups_train_subject = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data_subject = newsgroups_train_subject.data\n",
    "\n",
    "targets = newsgroups_train.target.tolist()\n",
    "target_names = newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Alghamdi, Rubayyi and Khalid Alfalqi. 2015. \"A Survey of Topic Modeling in Text Mining.\" *Int. J. Adv. Comput. Sci. Appl.(IJACSA)*, 6(1).\n",
    "\n",
    "Blei, David M. and John D. Lafferty. 2006. \"Dynamic Topic Models.\" In *Proceedings of the 23rd International Conference on Machine Learning* (pp. 113-120).\n",
    "\n",
    "https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883\n",
    "\n",
    "https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
