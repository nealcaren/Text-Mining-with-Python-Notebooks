{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Beyond LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling's ability to pick up on latent themes in large collections of texts can be quite useful (hence the model's popularity), LDA models nevertheless have a number of limitations. To name a few, LDA models don't account for the passage of time, the models have difficulty determining any relationships among generated topics, and topics become considerably less useful when the model is applied to shorter corpera with shorter document lengths.\n",
    "\n",
    "In this chapter, we'll present some alternative approaches to topic modeling that help to mitigate these limitations of LDA modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Topic Modeling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing Dynamic Topic Modeling, or DTM, [Blei and Lafferty](https://dl.acm.org/doi/pdf/10.1145/1143844.1143859) wanted to account for the possibility that content within a collection of texts could evolve over time, something traditional LDA topic modeling doesn't consider. To do so, they developed a form of topic modeling that could trace the evolution of the topics generated over time. In DTM, then, we can see our topics develop as time passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "\n",
    "In order to run Dynamic Topic Modeling in Python, we'll be installing the [Gensim](https://radimrehurek.com/gensim/index.html) topic modeling library. (We'll also want to make sure we've installed Gensim's dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Gensim, we'll import [ldaseq](https://radimrehurek.com/gensim/models/ldaseqmodel.html), the library's built-in Dynamic Topic Modeling function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaSeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some relavant parameters for `LdaSeqModel` are listed below. For an exhaustive list of parameters, see [here](https://radimrehurek.com/gensim/models/ldaseqmodel.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LdaSeqModel Parameters: \n",
    "\n",
    "- **corpus**: The collection of document vectors we'll use to fit our LDA Sequence model.\n",
    "\n",
    "\n",
    "- **id2word**: Allows us to map word IDs onto words, and helps determinine the size of our vocabulary.\n",
    "\n",
    "\n",
    "- **time_slice**: The number of documents we'd like to include within each period of time we want our model to consider. \n",
    "\n",
    "\n",
    "- **num_topics**: The total number of topics we'd like our model to determine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get a handle on the `LdaSeqModel` function, we'll run the model with gensim's common corpus and dictionary. We'll use the common dictionary for the `id2word` parameter when we run our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.test.utils import common_dictionary\n",
    "\n",
    "corpus = common_corpus\n",
    "dictionary = common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tmwp/lib/python3.8/site-packages/gensim/models/ldaseqmodel.py:293: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "ldaseq = LdaSeqModel(corpus=common_corpus, id2word=dictionary, time_slice=[2, 4, 3], num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, the topics generated with the Gensim common corpus and dictionary don't appear to vary much over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21157474442727292),\n",
       "  ('user', 0.16464543889319655),\n",
       "  ('computer', 0.11780520871853883),\n",
       "  ('interface', 0.11780520871853883),\n",
       "  ('eps', 0.06967385482884698),\n",
       "  ('response', 0.06951097868862414),\n",
       "  ('time', 0.06951097868862414),\n",
       "  ('survey', 0.051180555909905195),\n",
       "  ('trees', 0.032452567340626),\n",
       "  ('graph', 0.032452567340626),\n",
       "  ('minors', 0.032452567340626),\n",
       "  ('human', 0.030935329104574284)],\n",
       " [('trees', 0.32492222725659636),\n",
       "  ('graph', 0.3235563263440136),\n",
       "  ('minors', 0.2205714063302323),\n",
       "  ('computer', 0.0382488601600507),\n",
       "  ('survey', 0.022503013800186142),\n",
       "  ('human', 0.0100605551936047),\n",
       "  ('interface', 0.0100605551936047),\n",
       "  ('response', 0.0100605551936047),\n",
       "  ('time', 0.0100605551936047),\n",
       "  ('user', 0.0100605551936047),\n",
       "  ('system', 0.00994769507044868),\n",
       "  ('eps', 0.00994769507044868)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21240589151067885),\n",
       "  ('user', 0.1646899189988433),\n",
       "  ('computer', 0.11749357289440712),\n",
       "  ('interface', 0.11749357289440712),\n",
       "  ('eps', 0.06963604929122659),\n",
       "  ('response', 0.0694731541329969),\n",
       "  ('time', 0.0694731541329969),\n",
       "  ('survey', 0.05114236405938337),\n",
       "  ('trees', 0.03241859405373477),\n",
       "  ('graph', 0.03241859405373477),\n",
       "  ('minors', 0.03241859405373477),\n",
       "  ('human', 0.030936539923855384)],\n",
       " [('trees', 0.3249256535151684),\n",
       "  ('graph', 0.32373545741107845),\n",
       "  ('minors', 0.22060806640237762),\n",
       "  ('computer', 0.03819443709873786),\n",
       "  ('survey', 0.022472092171356966),\n",
       "  ('human', 0.010041390232247207),\n",
       "  ('interface', 0.010041390232247207),\n",
       "  ('response', 0.010041390232247207),\n",
       "  ('time', 0.010041390232247207),\n",
       "  ('user', 0.010041390232247207),\n",
       "  ('system', 0.00992867112002237),\n",
       "  ('eps', 0.00992867112002237)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21241936929164823),\n",
       "  ('user', 0.16472754916179352),\n",
       "  ('computer', 0.11755004609140896),\n",
       "  ('interface', 0.11755004609140896),\n",
       "  ('eps', 0.06960644191233825),\n",
       "  ('response', 0.06944356260480058),\n",
       "  ('time', 0.06944356260480058),\n",
       "  ('survey', 0.05111543816120229),\n",
       "  ('trees', 0.032396675636444675),\n",
       "  ('graph', 0.032396675636444675),\n",
       "  ('minors', 0.032396675636444675),\n",
       "  ('human', 0.030953957171264507)],\n",
       " [('graph', 0.32400816741793875),\n",
       "  ('trees', 0.32379355787054775),\n",
       "  ('minors', 0.22150884150941086),\n",
       "  ('computer', 0.038181772854098815),\n",
       "  ('survey', 0.0224696342220385),\n",
       "  ('human', 0.010037636236713735),\n",
       "  ('interface', 0.010037636236713735),\n",
       "  ('response', 0.010037636236713735),\n",
       "  ('time', 0.010037636236713735),\n",
       "  ('user', 0.010037636236713735),\n",
       "  ('system', 0.009924922471198317),\n",
       "  ('eps', 0.009924922471198317)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's alright: we have no reason to expect any changes! In order to see some real time variance, let's walk through how to apply LDA Sequence topic modeling to our UN general debate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "un_df = pd.read_json('un-general-debates.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = un_df['speech_year'] < 1989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3214\n",
       "unique        2\n",
       "top       False\n",
       "freq       1882\n",
       "Name: speech_year, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = un_df['speech_year'] > 1994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3214\n",
       "unique        2\n",
       "top       False\n",
       "freq       2323\n",
       "Name: speech_year, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_df = un_df[a == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-aced95c9270d>:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  un_df = un_df[b == False]\n"
     ]
    }
   ],
   "source": [
    "un_df = un_df[b == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(un_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     991.000000\n",
       "mean     1991.594349\n",
       "std         1.707656\n",
       "min      1989.000000\n",
       "25%      1990.000000\n",
       "50%      1992.000000\n",
       "75%      1993.000000\n",
       "max      1994.000000\n",
       "Name: speech_year, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df['speech_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Corpus\n",
    "\n",
    "[Corpora and Vector Spaces, Gensim style](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ﻿It is indeed a pleasure for me and the member...\n",
       "1       ﻿\\nMay I begin by congratulating you. Sir, on ...\n",
       "2       ﻿\\nMr. President, it is a particular pleasure ...\n",
       "3       ﻿\\nDuring the debate at the fortieth session o...\n",
       "4       ﻿I should like at the outset to express my del...\n",
       "                              ...                        \n",
       "3209    I should like to congratulate\\nMr. Essy on his...\n",
       "3210    It is with pleasure that I begin this speech b...\n",
       "3211    Allow me first of all, Sir, to congratulate yo...\n",
       "3212    It is a great pleasure to attend the beginning...\n",
       "3213    Your election,\\nSir, to the presidency of the ...\n",
       "Name: speech_text, Length: 3214, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df['speech_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying the CountVectorizer from sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase   = True,\n",
    "                             ngram_range = (1,1),\n",
    "                             max_df      = .90,\n",
    "                             stop_words   = 'english',\n",
    "                             max_features = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(un_df['speech_text'])\n",
    "un_word_counts = vectorizer.transform(un_df['speech_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Gensim link above, trying to convert to corpus\n",
    "\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.matutils import corpus2csc\n",
    "import scipy.sparse\n",
    "\n",
    "corpus = Sparse2Corpus(un_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3214x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1299630 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Our Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents to string\n",
    "\n",
    "documents = str(un_df['speech_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize with spacy\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(\"\\t\", token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gensim to create dictionary\n",
    "\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Time Slices\n",
    "\n",
    "Let's say we want to look at the evolution of our UN general debate topics by comparing speeches given in the three years before and three years after the fall of the Soviet Union:\n",
    "\n",
    "\n",
    "\n",
    "- 1989-1991 = 153+156+162 = **471**\n",
    "\n",
    "\n",
    "- 1992-1994 = 167+175+178 = **520**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = [471, 520]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together: Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I think this might be working but it's taking forever, as always\n",
    "\n",
    "ldaseq = LdaSeqModel(corpus=corpus, time_slice=time_slice, num_topics=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Text Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling works well when the texts in our corpus are considerably lengthy (around fifty words or more), LDA models run into some issues when applied to shorter texts. This happens because of a major assumption of LDA modeling: that each text is a *mixture of topics*. While this makes sense in the case of longer texts, shorter texts, like social media posts, often consist of only a *single topic*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on it...Code's giving me trouble but that's nothing new. \n",
    "\n",
    "import spacy\n",
    "import gsdmm\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['talk.politics.mideast', 'comp.windows.x', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "newsgroups_train_subject = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data_subject = newsgroups_train_subject.data\n",
    "\n",
    "targets = newsgroups_train.target.tolist()\n",
    "target_names = newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Alghamdi, Rubayyi and Khalid Alfalqi. 2015. \"A Survey of Topic Modeling in Text Mining.\" *Int. J. Adv. Comput. Sci. Appl.(IJACSA)*, 6(1).\n",
    "\n",
    "Blei, David M. and John D. Lafferty. 2006. \"Dynamic Topic Models.\" In *Proceedings of the 23rd International Conference on Machine Learning* (pp. 113-120).\n",
    "\n",
    "https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883\n",
    "\n",
    "https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
