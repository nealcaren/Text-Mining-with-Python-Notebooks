{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Beyond LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling's ability to pick up on latent themes in large collections of texts can be quite useful (hence the model's popularity), LDA models nevertheless have a number of limitations. To name a few, LDA models don't account for the passage of time, the models have difficulty determining any relationships among generated topics, and topics become considerably less useful when the model is applied to shorter corpera with shorter document lengths.\n",
    "\n",
    "In this chapter, we'll present some alternative approaches to topic modeling that help to mitigate these limitations of LDA modeling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Topic Modeling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In developing Dynamic Topic Modeling, or DTM, [Blei and Lafferty](https://dl.acm.org/doi/pdf/10.1145/1143844.1143859) wanted to account for the possibility that content within a collection of texts could evolve over time, something traditional LDA topic modeling doesn't consider. To do so, they developed a form of topic modeling that could trace the evolution of the topics generated over time. In DTM, then, we can see our topics develop as time passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim\n",
    "\n",
    "In order to run Dynamic Topic Modeling in Python, we'll be installing the [Gensim](https://radimrehurek.com/gensim/index.html) topic modeling library. (We'll also want to make sure we've installed Gensim's dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Gensim, we'll import [ldaseq](https://radimrehurek.com/gensim/models/ldaseqmodel.html), the library's built-in Dynamic Topic Modeling function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaSeqModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some relavant parameters for `LdaSeqModel` are listed below. For an exhaustive list of parameters, see [here](https://radimrehurek.com/gensim/models/ldaseqmodel.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LdaSeqModel Parameters: \n",
    "\n",
    "- **corpus**: The collection of document vectors we'll use to fit our LDA Sequence model.\n",
    "\n",
    "\n",
    "- **id2word**: Allows us to map word IDs onto words, and helps determinine the size of our vocabulary.\n",
    "\n",
    "\n",
    "\n",
    "- **time_slice**: The number of documents we'd like to include within each period of time we want our model to consider. \n",
    "\n",
    "\n",
    "- **num_topics**: The total number of topics we'd like our model to determine.\n",
    "\n",
    "\n",
    "- **passes**: This parameter functions in a similar manner to the `max_iter` parameter we set when running a conventional LDA model with scikit-learn. Like `max_iter`, `passes` is set to 10 by default. As was the case before, we'll almost always want to set `passes` to a number higher than 10.  \n",
    "\n",
    "\n",
    "- **em_max_iter**: Sets a maximum threshold on the number of iterations until we reach convergence of the  [Expectation-Maximization](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) algorithm.\n",
    "\n",
    "(*note to self: need a better link than Wikipedia*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get a handle on the `LdaSeqModel` function, we'll run the model with gensim's common corpus and dictionary. We'll use the common dictionary for the `id2word` parameter when we run our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus\n",
    "from gensim.test.utils import common_dictionary\n",
    "\n",
    "corpus = common_corpus\n",
    "dictionary = common_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tmwp/lib/python3.8/site-packages/gensim/models/ldaseqmodel.py:293: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    }
   ],
   "source": [
    "ldaseq = LdaSeqModel(corpus=common_corpus, id2word=dictionary, time_slice=[2, 4, 3], num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, the topics generated with the Gensim common corpus and dictionary don't appear to vary much over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21103477186241593),\n",
       "  ('user', 0.16397962016469478),\n",
       "  ('interface', 0.11745461526922607),\n",
       "  ('computer', 0.11727548956705906),\n",
       "  ('response', 0.0719533519106377),\n",
       "  ('time', 0.0719533519106377),\n",
       "  ('eps', 0.0719533519106377),\n",
       "  ('survey', 0.05147858004212989),\n",
       "  ('trees', 0.030901334149172184),\n",
       "  ('graph', 0.03071583509559593),\n",
       "  ('minors', 0.03071583509559593),\n",
       "  ('human', 0.03058386302219727)],\n",
       " [('trees', 0.3228488866688078),\n",
       "  ('graph', 0.322041720667678),\n",
       "  ('minors', 0.21890836764303392),\n",
       "  ('computer', 0.03684688982026238),\n",
       "  ('human', 0.017880791435300917),\n",
       "  ('interface', 0.017880791435300917),\n",
       "  ('survey', 0.017880791435300917),\n",
       "  ('response', 0.009142352178863018),\n",
       "  ('system', 0.009142352178863018),\n",
       "  ('time', 0.009142352178863018),\n",
       "  ('user', 0.009142352178863018),\n",
       "  ('eps', 0.009142352178863018)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21184048867551472),\n",
       "  ('user', 0.1640590986122984),\n",
       "  ('interface', 0.117102571455535),\n",
       "  ('computer', 0.11695025075276108),\n",
       "  ('response', 0.07192461562115725),\n",
       "  ('time', 0.07192461562115725),\n",
       "  ('eps', 0.07192461562115725),\n",
       "  ('survey', 0.0514466411016321),\n",
       "  ('trees', 0.03087175342171288),\n",
       "  ('graph', 0.030686309902832887),\n",
       "  ('minors', 0.030686309902832887),\n",
       "  ('human', 0.030582729311408343)],\n",
       " [('trees', 0.32293164889527337),\n",
       "  ('graph', 0.3221423932188621),\n",
       "  ('minors', 0.21897804755601968),\n",
       "  ('computer', 0.03678739908968738),\n",
       "  ('human', 0.017849582746292062),\n",
       "  ('interface', 0.017849582746292062),\n",
       "  ('survey', 0.017849582746292062),\n",
       "  ('response', 0.009122352600256255),\n",
       "  ('system', 0.009122352600256255),\n",
       "  ('time', 0.009122352600256255),\n",
       "  ('user', 0.009122352600256255),\n",
       "  ('eps', 0.009122352600256255)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('system', 0.21192796388747198),\n",
       "  ('user', 0.16410763095116246),\n",
       "  ('interface', 0.11710083582672116),\n",
       "  ('computer', 0.1170165264256437),\n",
       "  ('response', 0.0718891670848555),\n",
       "  ('time', 0.0718891670848555),\n",
       "  ('eps', 0.0718891670848555),\n",
       "  ('survey', 0.05141562743955698),\n",
       "  ('trees', 0.03084796899147348),\n",
       "  ('graph', 0.03066260767539272),\n",
       "  ('minors', 0.03066260767539272),\n",
       "  ('human', 0.030590729872618242)],\n",
       " [('graph', 0.3223834884555004),\n",
       "  ('trees', 0.32177799829599324),\n",
       "  ('minors', 0.21992300080023172),\n",
       "  ('computer', 0.036777841094811504),\n",
       "  ('human', 0.01784728082781973),\n",
       "  ('interface', 0.01784728082781973),\n",
       "  ('survey', 0.01784728082781973),\n",
       "  ('response', 0.009119165774000784),\n",
       "  ('system', 0.009119165774000784),\n",
       "  ('time', 0.009119165774000784),\n",
       "  ('user', 0.009119165774000784),\n",
       "  ('eps', 0.009119165774000784)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's alright: we have no reason to expect any changes! In order to see some real time variance, let's walk through how to apply LDA Sequence topic modeling to our UN general debate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "un_df = pd.read_json('un-general-debates.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be interesting to see how the results of our LDA Sequence model compare to what we saw with the `post-soviet` key when running a conventional LDA model with our UN data.\n",
    "\n",
    "\n",
    "To hone in on the transition from pre-Soviet to post-Soviet (and for the sake of limiting excessive run times), let's look specifically at the 660 documents in the UN dataset from the two years leading up to, and the two years following, the dissolution of the Soviet Union. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = un_df['speech_year'] < 1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = un_df['speech_year'] > 1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-0df7f11f4650>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  un_df = un_df[b == False]\n"
     ]
    }
   ],
   "source": [
    "un_df = un_df[a == False]\n",
    "un_df = un_df[b == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(un_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     660.000000\n",
       "mean     1991.546970\n",
       "std         1.119251\n",
       "min      1990.000000\n",
       "25%      1991.000000\n",
       "50%      1992.000000\n",
       "75%      1993.000000\n",
       "max      1993.000000\n",
       "Name: speech_year, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df['speech_year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Corpus\n",
    "\n",
    "[Corpora and Vector Spaces, Gensim style](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of text documents we're looking at is contained within the 'speech_text' key of our UN dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290     ﻿On behalf of my delegation and on my own beha...\n",
       "291     ﻿It is truly an honour for me to address a bod...\n",
       "292     ﻿Mr. President, allow me to begin by warmly co...\n",
       "293     ﻿At the outset, I would like to congratulate y...\n",
       "294     ﻿Mr. President, it is my high honour to addres...\n",
       "                              ...                        \n",
       "3031    ﻿On behalf of my Government and on my own beha...\n",
       "3032    ﻿\\nIt is a source of particular pleasure for m...\n",
       "3033    ﻿Mr. President, please accept my congratulatio...\n",
       "3034    ﻿Mr. President, allow me, at the outset of my ...\n",
       "3035    ﻿\\nOn behalf of the Malawi delegation. I have ...\n",
       "Name: speech_text, Length: 660, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_df['speech_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up our corpus with gensim, we'll define a function to iterate over each line of `speech_text`, and generate new tokenized words every time we hit white space. The `doc2bow` method available through gensim.dictionary lets us convert our documents into bag-of-words vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in un_df['speech_text']:\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One beneficial aspect of gensim is its ability to load one vectorized document within a corpus into memory at a time, rather than require the entire corpus be stored in RAM. This capability is particularly useful when looking at exceptionally large corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Corpus object at 0x1197ace50>\n"
     ]
    }
   ],
   "source": [
    "corpus_memory_friendly = Corpus()\n",
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Our Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our stoplist, we'll use the standard [\"english\"](https://gist.github.com/sebleier/554280) list of stopwords, in addition to \"also,\" \"united,\" \"nations,\" and \"-\". We'll also remove any words that occur in our corpus only once. We can use the `compactify` method to remove extra spaces between words after filtering our tokens for stop words and once-only occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO : built Dictionary(43938 unique tokens: ['(habitat),', '(unhcr)', '-', '--', '1960s']...) from 660 documents (total 2009288 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(24701 unique tokens: ['(habitat),', '(unhcr)', '1960s', '1970s', '1990s.']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from six import iteritems\n",
    "# collect statistics about all tokens\n",
    "dictionary = corpora.Dictionary(line.lower().split() for line in un_df['speech_text'])\n",
    "# remove stop words and words that appear only once\n",
    "stoplist = set('also - united nations i me my myself we our ours ourselves you your yours yourself yourselves he him his himself she her hers herself it its itself they them their theirs themselves what which who whom this that these those am is are was were be been being have has had having do does did doing a an the and but if or because as until while of at by for with about against between into through during before after above below to from up down in out on off over under again further then once here there when where why how all any both each few more most other some such no nor not only own same so than too very s t can will just don should now'.split())\n",
    "stop_ids = [\n",
    "    dictionary.token2id[stopword]\n",
    "    for stopword in stoplist\n",
    "    if stopword in dictionary.token2id\n",
    "]\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids) \n",
    "dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up our Time Slices\n",
    "\n",
    "Let's say we want to look at the evolution of our UN general debate topics over the two years leading up to, and the two years following, the dissolution of the Soviet Union:\n",
    "\n",
    "- 1990 = 156\n",
    "\n",
    "\n",
    "- 1991 = 162\n",
    "\n",
    "\n",
    "- 1992 = 167\n",
    "\n",
    "\n",
    "- 1993 = 175 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = [156,162, 167, 175]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together: Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "ldaseq = LdaSeqModel(corpus=corpus_memory_friendly, \n",
    "                     id2word=dictionary, \n",
    "                     time_slice=time_slice,\n",
    "                     passes = 50,\n",
    "                     em_max_iter=5,\n",
    "                     num_topics=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our model run, let's print out our topics over each time slice: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('world', 0.007490298177521934),\n",
       "  ('must', 0.006549445558411537),\n",
       "  ('new', 0.006244327471864768),\n",
       "  ('people', 0.005065612755036083),\n",
       "  ('international', 0.004782458186102162),\n",
       "  ('us', 0.0046574217503769135),\n",
       "  ('countries', 0.00441736467373003),\n",
       "  ('economic', 0.003935317468113478),\n",
       "  ('peace', 0.003810425712643679),\n",
       "  ('one', 0.0036811995633896245),\n",
       "  ('development', 0.003283022027559971),\n",
       "  ('many', 0.0031241478354439556),\n",
       "  ('human', 0.0030681736834799493),\n",
       "  ('states', 0.0029200976750825445),\n",
       "  ('country', 0.0027416360669084944),\n",
       "  ('government', 0.002739811942797668),\n",
       "  ('would', 0.0027223647105326146),\n",
       "  ('great', 0.0023232114841494427),\n",
       "  ('political', 0.002316781646675052),\n",
       "  ('democracy', 0.0023016256362888205)],\n",
       " [('international', 0.01321983465075864),\n",
       "  ('peace', 0.0063542257126587166),\n",
       "  ('world', 0.006285159993353706),\n",
       "  ('economic', 0.006241892643327187),\n",
       "  ('countries', 0.005843954519435114),\n",
       "  ('new', 0.004461861285234271),\n",
       "  ('security', 0.0042970183117730125),\n",
       "  ('development', 0.0042481486514130305),\n",
       "  ('people', 0.0038064483910988495),\n",
       "  ('efforts', 0.003786379039602986),\n",
       "  ('political', 0.0036880598298707503),\n",
       "  ('government', 0.003547138151380535),\n",
       "  ('community', 0.00324297308955233),\n",
       "  ('states', 0.003169300256218166),\n",
       "  ('developing', 0.0031004072093559687),\n",
       "  ('national', 0.0030554103260009412),\n",
       "  ('south', 0.003010981857099774),\n",
       "  ('african', 0.0028828705910955922),\n",
       "  ('general', 0.0027701992829773795),\n",
       "  ('hope', 0.002635237081387856)],\n",
       " [('international', 0.009608849349722556),\n",
       "  ('new', 0.006131343654603481),\n",
       "  ('human', 0.00606052153589569),\n",
       "  ('security', 0.005937414514707887),\n",
       "  ('world', 0.005772272344511421),\n",
       "  ('must', 0.005392444792479955),\n",
       "  ('general', 0.004188098274574914),\n",
       "  ('rights', 0.004174168615750726),\n",
       "  ('peace', 0.0041561255085395205),\n",
       "  ('economic', 0.004136365078712063),\n",
       "  ('states', 0.004046813211258469),\n",
       "  ('political', 0.003495123433567402),\n",
       "  ('development', 0.0030946318973865037),\n",
       "  ('would', 0.0029918261815742183),\n",
       "  ('assembly', 0.00295214396102229),\n",
       "  ('community', 0.002907106895527861),\n",
       "  ('countries', 0.002889069103497946),\n",
       "  ('cooperation', 0.002859512138558852),\n",
       "  ('social', 0.0026855471356001265),\n",
       "  ('conference', 0.0026249203803492935)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('world', 0.007525992417898458),\n",
       "  ('must', 0.006582235531003249),\n",
       "  ('new', 0.006263348248554922),\n",
       "  ('people', 0.005084335863601741),\n",
       "  ('us', 0.004720532439211315),\n",
       "  ('international', 0.004683729390100844),\n",
       "  ('countries', 0.00464784511820726),\n",
       "  ('economic', 0.003946587705482039),\n",
       "  ('peace', 0.0038322201217897227),\n",
       "  ('one', 0.0035345891444205314),\n",
       "  ('development', 0.0032953394919181932),\n",
       "  ('many', 0.0031375508863386984),\n",
       "  ('human', 0.003076328958185783),\n",
       "  ('states', 0.0029161221191692983),\n",
       "  ('government', 0.0028056633569699782),\n",
       "  ('country', 0.00275339162228974),\n",
       "  ('would', 0.0027306122051111415),\n",
       "  ('political', 0.0023248312961721843),\n",
       "  ('great', 0.0023052407832702985),\n",
       "  ('democracy', 0.002302915573184192)],\n",
       " [('international', 0.013263640291491588),\n",
       "  ('peace', 0.006364334340705556),\n",
       "  ('world', 0.006300332278450357),\n",
       "  ('economic', 0.006254516533521765),\n",
       "  ('countries', 0.005863526302179306),\n",
       "  ('new', 0.004466224275532365),\n",
       "  ('security', 0.004312423124295029),\n",
       "  ('development', 0.0042645966351185114),\n",
       "  ('people', 0.0038053443384179915),\n",
       "  ('efforts', 0.0037921094228861815),\n",
       "  ('political', 0.003700682880277774),\n",
       "  ('government', 0.0035568993519814146),\n",
       "  ('community', 0.0032698378430457403),\n",
       "  ('states', 0.0031668872534415028),\n",
       "  ('developing', 0.003109493589085759),\n",
       "  ('national', 0.003060362732298004),\n",
       "  ('south', 0.003020490844118916),\n",
       "  ('african', 0.0028865407684330185),\n",
       "  ('general', 0.002788626216487418),\n",
       "  ('hope', 0.002639398527244926)],\n",
       " [('international', 0.009643018512781067),\n",
       "  ('new', 0.006144597587156077),\n",
       "  ('human', 0.006075215702775787),\n",
       "  ('security', 0.005962095855334134),\n",
       "  ('world', 0.005427699046913662),\n",
       "  ('must', 0.005414375944342223),\n",
       "  ('peace', 0.004184714378272811),\n",
       "  ('rights', 0.004182409719398513),\n",
       "  ('economic', 0.0041495403476029405),\n",
       "  ('general', 0.004123871230173883),\n",
       "  ('states', 0.0040570190714639244),\n",
       "  ('political', 0.0034798328148759987),\n",
       "  ('development', 0.0033259693375357062),\n",
       "  ('council', 0.003073718879417292),\n",
       "  ('would', 0.0029997310270297047),\n",
       "  ('assembly', 0.0029626238439396497),\n",
       "  ('community', 0.0029157795195933318),\n",
       "  ('countries', 0.0028923525271017264),\n",
       "  ('cooperation', 0.002861622417431288),\n",
       "  ('session', 0.002788761267131617)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('world', 0.0075775231516884934),\n",
       "  ('must', 0.00662442830134853),\n",
       "  ('new', 0.006290277434746623),\n",
       "  ('people', 0.005105871080849557),\n",
       "  ('us', 0.004785919739885581),\n",
       "  ('international', 0.004779281630947735),\n",
       "  ('countries', 0.004512687256552781),\n",
       "  ('economic', 0.00396164956260618),\n",
       "  ('peace', 0.0038550855010333488),\n",
       "  ('one', 0.003600677408349859),\n",
       "  ('development', 0.0033080532555901155),\n",
       "  ('many', 0.0031506057200634116),\n",
       "  ('human', 0.003086249424135719),\n",
       "  ('states', 0.002912197783690612),\n",
       "  ('country', 0.0027687833421748314),\n",
       "  ('would', 0.0027416723854016673),\n",
       "  ('government', 0.002734371687995242),\n",
       "  ('political', 0.0023368886596403563),\n",
       "  ('democracy', 0.0023037558366195486),\n",
       "  ('time', 0.0022978147038505495)],\n",
       " [('international', 0.013328639855462922),\n",
       "  ('peace', 0.0063767628996250995),\n",
       "  ('world', 0.006327077941908732),\n",
       "  ('economic', 0.0062755822361628055),\n",
       "  ('countries', 0.005897229696867381),\n",
       "  ('new', 0.004478791165627977),\n",
       "  ('security', 0.004336200959949073),\n",
       "  ('development', 0.004273581237550927),\n",
       "  ('efforts', 0.003803944015896001),\n",
       "  ('people', 0.0037495811287812323),\n",
       "  ('political', 0.0037257080084250956),\n",
       "  ('government', 0.0035573180430556886),\n",
       "  ('community', 0.0032811574726072665),\n",
       "  ('states', 0.0031669304640401606),\n",
       "  ('developing', 0.003126570892719704),\n",
       "  ('national', 0.003068789907647167),\n",
       "  ('south', 0.00303920499397799),\n",
       "  ('african', 0.0028914891483446787),\n",
       "  ('general', 0.002761885261446412),\n",
       "  ('hope', 0.002648255877248033)],\n",
       " [('international', 0.009716057010563543),\n",
       "  ('new', 0.006186255270852226),\n",
       "  ('human', 0.006110223836620154),\n",
       "  ('security', 0.006012513844715081),\n",
       "  ('world', 0.0054997667646930135),\n",
       "  ('must', 0.005461372273826389),\n",
       "  ('rights', 0.004205795848810816),\n",
       "  ('economic', 0.004179815679673834),\n",
       "  ('states', 0.004082493110110416),\n",
       "  ('peace', 0.00385317438528834),\n",
       "  ('general', 0.00356654281329154),\n",
       "  ('political', 0.0034831742681545423),\n",
       "  ('development', 0.003198417779943876),\n",
       "  ('would', 0.003019762642835083),\n",
       "  ('community', 0.0029426259465152966),\n",
       "  ('countries', 0.002916007677045231),\n",
       "  ('cooperation', 0.0028703846301593103),\n",
       "  ('council', 0.0027522496305743805),\n",
       "  ('conference', 0.0026589937889004334),\n",
       "  ('assembly', 0.002602758054458816)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('world', 0.007616953171275815),\n",
       "  ('must', 0.006653124321057768),\n",
       "  ('new', 0.006310910319582272),\n",
       "  ('people', 0.005119295611629798),\n",
       "  ('international', 0.004823005642591637),\n",
       "  ('us', 0.004765673362271388),\n",
       "  ('countries', 0.00452653672569581),\n",
       "  ('economic', 0.003972867164769877),\n",
       "  ('peace', 0.0038671806577720244),\n",
       "  ('one', 0.0036617806005182526),\n",
       "  ('development', 0.0033150915238955897),\n",
       "  ('many', 0.0031589858443702664),\n",
       "  ('human', 0.0030926678068101507),\n",
       "  ('states', 0.0029093833647568863),\n",
       "  ('country', 0.0027794168368489086),\n",
       "  ('would', 0.0027494802795279788),\n",
       "  ('government', 0.0026818455708699667),\n",
       "  ('political', 0.002347128882270167),\n",
       "  ('time', 0.0023185411694922804),\n",
       "  ('democracy', 0.002304950773052879)],\n",
       " [('international', 0.013387531182957),\n",
       "  ('peace', 0.006388295625500919),\n",
       "  ('world', 0.006351946564518667),\n",
       "  ('economic', 0.006296760212557907),\n",
       "  ('countries', 0.005929076957719861),\n",
       "  ('new', 0.004491391541158278),\n",
       "  ('security', 0.004357861642997383),\n",
       "  ('development', 0.0042714709581994645),\n",
       "  ('efforts', 0.003815608255572427),\n",
       "  ('political', 0.003752957270428758),\n",
       "  ('people', 0.0037002645526938802),\n",
       "  ('government', 0.003552748258705285),\n",
       "  ('community', 0.003251991839258677),\n",
       "  ('states', 0.003170177549285804),\n",
       "  ('developing', 0.003142568356008408),\n",
       "  ('national', 0.003077632989511127),\n",
       "  ('south', 0.003057686587359041),\n",
       "  ('african', 0.0028963359299825904),\n",
       "  ('general', 0.0027383527530069644),\n",
       "  ('hope', 0.0026577650766451016)],\n",
       " [('international', 0.00976120871429212),\n",
       "  ('new', 0.006214975371618454),\n",
       "  ('human', 0.006132518874651683),\n",
       "  ('security', 0.006048854567766299),\n",
       "  ('world', 0.005624161237391942),\n",
       "  ('must', 0.005494704830922478),\n",
       "  ('rights', 0.004221144279612392),\n",
       "  ('economic', 0.0041996131546304105),\n",
       "  ('states', 0.004099005593816144),\n",
       "  ('peace', 0.003501227542032932),\n",
       "  ('political', 0.003496027626589648),\n",
       "  ('general', 0.003145815649151661),\n",
       "  ('would', 0.0030324722361457137),\n",
       "  ('development', 0.0029919357564086265),\n",
       "  ('community', 0.00296130801027043),\n",
       "  ('countries', 0.0029419716374264574),\n",
       "  ('cooperation', 0.0028728547794688443),\n",
       "  ('council', 0.0028297799928070815),\n",
       "  ('important', 0.0027064388725964736),\n",
       "  ('conference', 0.0026782132551337982)]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaseq.print_topics(time=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Short Text Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While LDA topic modeling works well when the texts in our corpus are considerably lengthy (around fifty words or more), LDA models run into some issues when applied to shorter texts. This happens because of a major assumption of LDA modeling: that each text is a *mixture of topics*. While this makes sense in the case of longer texts, shorter texts, like social media posts, often consist of only a *single topic*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import gsdmm\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['talk.politics.mideast', 'comp.windows.x', 'sci.space']\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "newsgroups_train_subject = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data_subject = newsgroups_train_subject.data\n",
    "\n",
    "targets = newsgroups_train.target.tolist()\n",
    "target_names = newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Alghamdi, Rubayyi and Khalid Alfalqi. 2015. \"A Survey of Topic Modeling in Text Mining.\" *Int. J. Adv. Comput. Sci. Appl.(IJACSA)*, 6(1).\n",
    "\n",
    "Blei, David M. and John D. Lafferty. 2006. \"Dynamic Topic Models.\" In *Proceedings of the 23rd International Conference on Machine Learning* (pp. 113-120).\n",
    "\n",
    "https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883\n",
    "\n",
    "https://markroxor.github.io/gensim/static/notebooks/ldaseqmodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
