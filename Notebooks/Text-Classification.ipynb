{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we'll go over how to perform *text classification* with Python. As another form of natural language processing, text classification will allow us to automatically assign a set of pre-determined categories, or tags, to  unstructured texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get started by installing `matplotlib` and importing `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we'll be looking at a dataset containing [reviews](https://www.kaggle.com/zynicide/wine-reviews/data) from Wine Enthusiast magazine.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/zynicide/wine-reviews/data\n",
    "\n",
    "wine_df = pd.read_csv('wine_reviews.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly get a sense of the distribution of reviews by looking at the `value_counts` associated with different `point` scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87     16933\n",
       "86     12600\n",
       "91     11359\n",
       "92      9613\n",
       "85      9530\n",
       "93      6489\n",
       "84      6480\n",
       "94      3758\n",
       "83      3025\n",
       "82      1836\n",
       "95      1535\n",
       "81       692\n",
       "96       523\n",
       "80       397\n",
       "97       229\n",
       "98        77\n",
       "99        33\n",
       "100       19\n",
       "Name: points, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['points'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could also be helpful for us to read over a few of the `descriptions` of the wines. However, since `pandas` defaults to a maximum column width of 50 characters, it's difficult to glean much from each review without specifying a longer maximum character width for the columns in our dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aromas include tropical fruit, broom, brimston...\n",
       "1    This is ripe and fruity, a wine that is smooth...\n",
       "2    Tart and snappy, the flavors of lime flesh and...\n",
       "3    Pineapple rind, lemon pith and orange blossom ...\n",
       "4    Much like the regular bottling from 2012, this...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['description'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![google_search.png](images/google_search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `set_options` function in `pandas` to set our maximum column width to 120 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll have more text to work with when we're looking at the first five descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripen...\n",
       "1    This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red be...\n",
       "2    Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity...\n",
       "3    Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of ...\n",
       "4    Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['description'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `head` function to see all the keys included in the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripen...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red be...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling (Lake Michigan Shore)</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal ...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child Block Pinot Noir (Willamette Valley)</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  \\\n",
       "0     Italy   \n",
       "1  Portugal   \n",
       "2        US   \n",
       "3        US   \n",
       "4        US   \n",
       "\n",
       "                                                                                                               description  \\\n",
       "0  Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripen...   \n",
       "1  This is ripe and fruity, a wine that is smooth while still structured. Firm tannins are filled out with juicy red be...   \n",
       "2  Tart and snappy, the flavors of lime flesh and rind dominate. Some green pineapple pokes through, with crisp acidity...   \n",
       "3  Pineapple rind, lemon pith and orange blossom start off the aromas. The palate is a bit more opulent, with notes of ...   \n",
       "4  Much like the regular bottling from 2012, this comes across as rather rough and tannic, with rustic, earthy, herbal ...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle  \\\n",
       "0          @kerinokeefe   \n",
       "1            @vossroger   \n",
       "2           @paulgwine    \n",
       "3                   NaN   \n",
       "4           @paulgwine    \n",
       "\n",
       "                                                                                 title  \\\n",
       "0                                                    Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1                                        Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2                                        Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                  St. Julian 2013 Reserve Late Harvest Riesling (Lake Michigan Shore)   \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child Block Pinot Noir (Willamette Valley)   \n",
       "\n",
       "          variety               winery rating  \n",
       "0     White Blend              Nicosia    Low  \n",
       "1  Portuguese Red  Quinta dos Avidagos    Low  \n",
       "2      Pinot Gris            Rainstorm    Low  \n",
       "3        Riesling           St. Julian    Low  \n",
       "4      Pinot Noir         Sweet Cheeks    Low  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Texts in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections will walk us through a step-by-step guide of how to classify texts in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Turning words into features\n",
    "\n",
    "In order to classify our texts, we'll need to convert each text document in our corpus into a fixed-length *vector*. We can accomplish this using the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html?highlight=vectorizer#sklearn.feature_extraction.text.CountVectorizer) function available through the scikit-learn library. Using `CountVectorizer`, we'll be able to transform the texts in our wine review dataframe into a matrix of token counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1) Set up your model, fixing any parameters.\n",
    "\n",
    "`CountVectorizer` can take a number of parameters; while not an exhaustive list, some important parameters are described below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CountVectorizer` Parameters\n",
    "\n",
    "- **lowercase**: Converts all text to lower case. By default, `lowercase` is set to True.\n",
    "\n",
    "\n",
    "- **ngram_range**: This allows us to restrict the range of n-values for our n-grams. Formatted as a tuple, the first sets the minimum n-value, and the second sets the maximum n-value. By default, `n-gram range` is set to (1,1). (If we leave it alone, we'll only be looking at unigrams.) \n",
    "\n",
    "\n",
    "- **stop_words**: We can use this parameter to rule out words that occur 1) too frequently, 2) not frequently enough, and/or 3) fall outside of a threshold term frequency. This can be set the 'english' to use a pre-determined set of stopwords often found in texts written in the English language. We can also provide our own list of stopwords if we so choose. \n",
    "\n",
    "> - **max_df**: Allows us to set a maximum threshold on document frequency for our terms incorporated into our vocabulary. By default, `max_df` is set to 1.0. \n",
    "> - **min_df**: Allows us to set a minimum threshold on document frequency for our terms incorporated into our vocabulary. By default, `min_df` is set to 1.0. \n",
    "> - **max_features**: Allows us to build a vocabulary exclusively from high-frequency terms occuring throughout our corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll convert our text to lower case, look only at unigrams, use \"english\" stopwords, and set a minimum document frequency for terms of .01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase   = True,\n",
    "                             ngram_range = (1,1),\n",
    "                             stop_words  = 'english',\n",
    "                             min_df      = .01,\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2) Fit your model\n",
    "\n",
    "We'll `fit` the vectorizer we've created to the `description` key in our wine review dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`model.fit(X)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(wine_df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use the `len` function to see how many features were generated when applying the vectorizor to our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3) Create new data based on your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can `transform` the text documents in the `description` key of our wine review dataframe into a document-term matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "review_word_counts = vectorizer.transform(wine_df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the value counts for the dummy variable `rating` in our dataframe.\n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low     51493\n",
       "High    33635\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4) Set up your (second) model, fixing any parameters.\n",
    "\n",
    "#### Multinomial NB\n",
    "Also imported from the scikit-learn library, [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB) uses the naive Bayes algorithm to classify multinomially distributed data. This classifier is well-suited to the token counts we've previously generated with our vectorizer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Fit your (second) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we `fit` the classifier to our data, we'll have to specify a couple of **parameters**: \n",
    "\n",
    "- **X**: These are the *training* vectors for our model. For our wine review data, we'll use our `review_word_counts` as our training vectors.\n",
    "\n",
    "\n",
    "\n",
    "- **Y**: These are the *target* values for our model. For our wine review data, we'll use the `high_rating` key to determine the target values for our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`model.fit(X)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`model.fit(X, Y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(review_word_counts, wine_df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now view a list of coefficients associated with each of our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.33467081,  -7.24590289,  -7.19142933,  -7.20616256,\n",
       "        -7.38885524,  -8.18761044,  -8.89070795, -11.09798286,\n",
       "        -7.20061213,  -7.24397425,  -6.69237287,  -4.00593826,\n",
       "        -6.70465667,  -7.24397425,  -7.25950854,  -6.263145  ,\n",
       "        -6.67477066,  -6.92639671,  -6.56148092,  -6.14471991,\n",
       "        -6.39337878,  -6.09342661,  -7.16437628,  -4.84345499,\n",
       "        -6.96645929,  -6.27185332,  -7.04067957,  -3.78998822,\n",
       "        -6.93484747,  -6.76128647,  -5.86105745,  -7.28728811,\n",
       "        -6.39585097,  -7.30147274,  -6.26459113,  -5.88949074,\n",
       "        -6.73083916,  -7.12085331,  -8.99606846,  -9.17839002,\n",
       "        -6.77928336,  -4.62605818,  -6.80255446,  -7.28127003,\n",
       "        -6.45534174,  -5.38365017,  -5.85864374,  -4.66095875,\n",
       "        -6.82131674,  -5.29641393,  -6.28284647,  -5.05147071,\n",
       "        -7.33256333,  -7.57162234,  -6.77807344,  -5.25233262,\n",
       "        -6.4614902 ,  -7.22300113,  -7.28127003,  -6.99910314,\n",
       "        -6.93202261,  -6.6704181 ,  -5.11679824,  -6.92639671,\n",
       "        -6.60120809,  -7.02817941,  -6.90970648,  -5.45898136,\n",
       "        -6.25953879,  -6.94337025,  -6.60019543,  -6.97231583,\n",
       "        -6.67368074,  -6.92639671,  -8.24885406,  -5.35585418,\n",
       "        -5.83765061,  -6.17138815,  -4.27578547,  -7.14499242,\n",
       "        -5.76966548,  -6.77084449,  -6.78779405,  -4.92438617,\n",
       "        -6.89600763,  -7.57429971,  -5.50665672,  -6.73894574,\n",
       "        -6.66392457,  -7.36248009,  -6.42855828,  -6.28505968,\n",
       "        -6.03022282,  -6.31276643,  -6.62064605,  -7.24783526,\n",
       "        -6.96063686,  -6.76605406,  -7.01583357,  -7.06133161,\n",
       "        -6.71029049,  -6.71937114,  -5.85479388,  -4.80154344,\n",
       "        -7.04698874,  -5.67423501,  -6.93909978,  -6.87981295,\n",
       "        -5.63530735,  -7.44143879,  -6.60934649,  -6.80007922,\n",
       "        -6.5595354 ,  -6.69793772,  -7.28728811,  -7.23057692,\n",
       "        -7.82255487,  -6.81376954,  -6.74594694,  -5.74741811,\n",
       "        -4.30921589,  -6.14087621,  -7.07425586,  -4.5923347 ,\n",
       "        -6.65319485,  -6.59012486,  -5.8944758 ,  -5.40823784,\n",
       "        -6.27696842,  -7.73382675,  -6.93061316,  -6.48106378,\n",
       "        -7.04698874,  -6.99158996,  -7.37558071,  -7.10061653,\n",
       "        -7.26343012,  -5.86882072,  -5.67865535,  -6.2459526 ,\n",
       "        -3.93059431,  -6.04579856,  -7.30761401,  -6.00367509,\n",
       "        -5.63878427,  -6.97820686,  -3.2928417 ,  -6.26459113,\n",
       "        -6.47747633,  -6.96938327,  -8.22287857,  -6.49372218,\n",
       "        -6.8520884 ,  -7.59598078,  -6.53363467,  -7.02507863,\n",
       "        -6.81251719,  -7.17510984,  -4.62241008,  -6.51023631,\n",
       "        -3.71517988,  -6.61755166,  -5.08005344,  -4.95653214,\n",
       "        -7.05015831,  -6.33580892,  -7.05015831,  -7.01583357,\n",
       "        -5.10606387,  -6.59514747,  -6.14664731,  -6.52327188,\n",
       "        -6.65747293,  -4.95888231,  -7.0066732 ,  -6.93626289,\n",
       "        -7.71513462,  -6.31885937,  -6.23114795,  -5.97077739,\n",
       "        -5.341953  ,  -6.24808555,  -6.13069801,  -5.71641117,\n",
       "        -6.0574946 ,  -6.2283527 ,  -6.82384519,  -8.7337042 ,\n",
       "        -7.71205295,  -6.85469596,  -7.23821054,  -6.52514805,\n",
       "        -6.20695044,  -6.99910314,  -5.54467098,  -5.76131929,\n",
       "        -7.86825702,  -7.3516925 ,  -5.98599507,  -7.40910341,\n",
       "        -6.09770404,  -6.30144128,  -5.36670314,  -7.73382675,\n",
       "        -6.37867263,  -4.70226606,  -6.0983166 ,  -5.25602072,\n",
       "        -5.78612127,  -7.55834193,  -5.70146693,  -6.07052025,\n",
       "        -6.74010921,  -7.00212429,  -8.26476952,  -6.94765903,\n",
       "        -7.48706495,  -6.41165171,  -6.702412  ,  -6.84948762,\n",
       "        -6.85339133,  -6.96792021,  -5.44485592,  -5.80559211,\n",
       "        -5.85095879,  -7.36465164,  -6.61344066,  -6.17535117,\n",
       "        -7.07425586,  -6.85339133,  -6.92639671,  -6.90695165,\n",
       "        -7.09396094,  -5.56891459,  -5.8830471 ,  -6.99458846,\n",
       "        -7.02817941,  -6.61652233,  -6.28653788,  -7.16082388,\n",
       "        -6.39998491,  -4.75027528,  -5.67183212,  -4.66518893,\n",
       "        -4.6986319 ,  -6.2459526 ,  -6.85469596,  -5.05297755,\n",
       "        -7.28327204,  -7.25365487,  -7.0036383 ,  -5.93631864,\n",
       "        -8.6675644 ,  -5.76526407,  -6.78657379,  -7.55570688,\n",
       "        -6.25953879,  -3.97101903,  -5.3208936 ,  -5.51825303,\n",
       "        -7.03597368,  -5.50665672,  -6.63626323,  -6.70690639,\n",
       "        -7.36465164,  -7.05015831,  -6.01432243,  -6.79884388,\n",
       "        -5.62380415,  -6.54794106,  -6.37059504,  -4.88046989,\n",
       "        -7.05972776,  -7.64080621,  -7.79878465,  -8.18761044,\n",
       "        -7.66987803,  -7.75287494,  -6.19203491,  -6.60019543,\n",
       "        -7.53229879,  -7.87547727,  -7.83988632,  -6.87847515,\n",
       "        -7.48706495,  -7.86825702,  -6.84689358,  -6.3196236 ,\n",
       "        -6.97673084,  -7.26934146,  -5.31303942,  -6.78779405,\n",
       "        -5.67543862,  -4.40533532,  -6.20695044,  -5.30082044,\n",
       "        -6.4676767 ,  -6.84689358,  -6.93768033,  -4.53233384,\n",
       "        -7.40005357,  -6.50194516,  -7.27927203,  -6.48827752,\n",
       "        -6.19608077,  -6.6682489 ,  -6.61755166,  -7.35815108,\n",
       "        -6.83146911,  -5.62724124,  -6.37220535,  -6.47301005,\n",
       "        -7.69375976,  -7.36900895,  -6.39255607,  -6.55468808,\n",
       "        -6.56538337,  -5.28439522,  -6.81502345,  -5.348011  ,\n",
       "        -7.64367565,  -6.95629218,  -5.53940133,  -6.67586177,\n",
       "        -6.82511181,  -6.22974935,  -5.86009127,  -4.62115037,\n",
       "        -6.34989366,  -6.71595622,  -6.83530298,  -6.27185332,\n",
       "        -4.84170949,  -6.91246891,  -5.67183212,  -6.32115382,\n",
       "        -6.53933269,  -6.05573145,  -6.54794106,  -5.97239682,\n",
       "        -6.8430151 ,  -5.68755508,  -6.96354384,  -6.63941615,\n",
       "        -7.56098394,  -4.6830347 ,  -6.39915675,  -6.01883966,\n",
       "        -6.88249391,  -6.31428619,  -5.67183212,  -7.0051546 ,\n",
       "        -4.37644764,  -5.58382124,  -6.64046933,  -5.76000781,\n",
       "        -7.25755351,  -5.23641994,  -6.92080229,  -6.11437624,\n",
       "        -8.05779882,  -6.68243353,  -5.98818805,  -6.60628682,\n",
       "        -6.76844641,  -6.37301147,  -6.80255446,  -6.51023631,\n",
       "        -5.30496925,  -7.25171123,  -6.0307954 ,  -7.30556273,\n",
       "        -5.15566081,  -7.01583357,  -7.00819411,  -8.2973811 ,\n",
       "        -7.43209292,  -7.15024177,  -7.79209566,  -6.78292193,\n",
       "        -7.62376034,  -6.55759365,  -7.55570688,  -6.50194516,\n",
       "        -6.60934649,  -6.37705188,  -7.27727801,  -6.94765903,\n",
       "        -5.01659451,  -6.52420953,  -3.2604285 ,  -7.35384073,\n",
       "        -6.92499517,  -5.85383373,  -7.07263117,  -6.63836407,\n",
       "        -6.35147095,  -6.36098728,  -6.58214078,  -6.49645566])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "coeficients = pd.Series(nb_classifier.coef_[0],\n",
    "                        index = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sort_values` lets us view the top terms used to describe the wines reviewed in our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022          -11.097983\n",
       "beautifully    -9.178390\n",
       "beautiful      -8.996068\n",
       "2020           -8.890708\n",
       "impressive     -8.733704\n",
       "opulent        -8.667564\n",
       "velvety        -8.297381\n",
       "lovely         -8.264770\n",
       "cellar         -8.248854\n",
       "focused        -8.222879\n",
       "potential      -8.187610\n",
       "2019           -8.187610\n",
       "tightly        -8.057799\n",
       "producer       -7.875477\n",
       "layered        -7.868257\n",
       "purple         -7.868257\n",
       "provide        -7.839886\n",
       "develop        -7.822555\n",
       "polished       -7.798785\n",
       "vines          -7.792096\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeficients.sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Exercise 1\n",
    "\n",
    "Construct a model of UN speeches to distinquish between those before and after the collapse of the Soviet Union.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5) Create new data based on your (second) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our classifier can now be used to `predict` whether a wine received a relatively `High` or `Low` rating, based on the words used to describe the wine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low', 'High', 'Low', ..., 'Low', 'High', 'High'], dtype='<U4')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.predict(review_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "wine_df['prediction']  = nb_classifier.predict(review_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a crosstab with `pandas` to quickly get a feel for how accurately our classifier predicts `High` and `Low` reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prediction</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>26996</td>\n",
       "      <td>6639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>7884</td>\n",
       "      <td>43609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prediction   High    Low\n",
       "rating                  \n",
       "High        26996   6639\n",
       "Low          7884  43609"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(wine_df['rating'], wine_df['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more detailed visualizations of prediction accuracy, we can import `classification_report`, `confusion_matrix`, and `accuracy_score` from scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score), we can get a numerical indicator of prediction accuracy, rather than just eyeball using a crosstab. We'll need to specify the following:\n",
    "\n",
    "- **y_true**: The correct labels our model is trying to predict. For this example, we'll set `y_true` to `rating`.  \n",
    "\n",
    "\n",
    "- **y_pred**:  The labels predicted by our classifier. For this example, we'll set `y_pred` to `prediction`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293980828869467"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(wine_df['rating'], wine_df['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Running a [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion_matrix#sklearn.metrics.confusion_matrix) produces results similar to the crosstab we generated earlier. However, through the us of the [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function available through the seaborn library, we can create a visual representation of the degree of prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115622d68>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(wine_df['rating'], wine_df['prediction'])\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, we can generate a [classification_report](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report) to return a text report with some helpful classification metrics.\n",
    "\n",
    "- **Precision**: % of selected items that are correct \n",
    "\n",
    "\n",
    "\n",
    "- **Recall**: % of correct items that are selected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.77      0.80      0.79     33635\n",
      "         Low       0.87      0.85      0.86     51493\n",
      "\n",
      "    accuracy                           0.83     85128\n",
      "   macro avg       0.82      0.82      0.82     85128\n",
      "weighted avg       0.83      0.83      0.83     85128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(wine_df['rating'], wine_df['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use our classifer to generate an array of probabilities that each of our features will occur in any given wine review, depending on whether a review is associated with a `High` or `Low` score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05837039, 0.94162961],\n",
       "       [0.8189896 , 0.1810104 ],\n",
       "       [0.0073304 , 0.9926696 ],\n",
       "       ...,\n",
       "       [0.31987064, 0.68012936],\n",
       "       [0.92064944, 0.07935056],\n",
       "       [0.65113375, 0.34886625]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.predict_proba(review_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame(nb_classifier.predict_proba(review_word_counts), \n",
    "                          columns=nb_classifier.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058370</td>\n",
       "      <td>0.941630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818990</td>\n",
       "      <td>0.181010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.992670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.990035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.982221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       High       Low\n",
       "0  0.058370  0.941630\n",
       "1  0.818990  0.181010\n",
       "2  0.007330  0.992670\n",
       "3  0.009965  0.990035\n",
       "4  0.017779  0.982221"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wine_df_prediction = pd.concat([wine_df, predict_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>A blend of 28% Cabernet Franc, 23% Cabernet Sauvignon, 21% Malbec, 18% Petit Verdot and 10% Merlot, this is a big, b...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>A proprietary blend of 57% Merlot, 35% Cabernet Sauvignon and 8% Petit Verdot, all homegrown, this is dense and powe...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8339</th>\n",
       "      <td>Dark, rich mountain blueberry and blackberry form the core of this classically delicious Napa Valley wine from an es...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>A beautifully dense, ripe wine, its intense acidity balanced by an opulent structure and gorgeous fruits. The textur...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>From one of the top estates in Cahors, this complex, dense wine is both structured and packed with great fruit. At t...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9552</th>\n",
       "      <td>Aged for a year in new wood barrels, this powerful, concentrated wine shows both richness and considerable aging pot...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>This wine is opulent and rich without losing sight of the freshness of the vintage. Layers of new wood (100%) are bl...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>Power and elegance come together in this beautifully proportioned, flavorful and pure-tasting wine. It has depth, co...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>A rare reserve-level Cabernet only made once before, this 100% varietal wine hails from esteemed Kiona and Ciel du C...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>One of Italy's most acclaimed Merlots, this concentrated wine opens with scents of black currants, cedar, sage and e...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Made from 100% Corvina, this shows the great potential of this native grape. It boasts rich blackberry, plum and lic...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>A blend of 78% Cabernet Sauvignon, 12% Petit Verdot, 5% Merlot and 5% Malbec, this is a tight, focused selection, wi...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>Great vineyards, great winery, great vintage: There's lots to like about this big, bold, fruity wine that manages to...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>Enticing scents of iris, violet, menthol and exotic spice emerge in the glass. Elegant and fresh, the polished, deli...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>Trefethen has been on a roll the last few years, producing some of Napa's most spectacular Cabernets. This bottling,...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  description  \\\n",
       "4661  A blend of 28% Cabernet Franc, 23% Cabernet Sauvignon, 21% Malbec, 18% Petit Verdot and 10% Merlot, this is a big, b...   \n",
       "9681  A proprietary blend of 57% Merlot, 35% Cabernet Sauvignon and 8% Petit Verdot, all homegrown, this is dense and powe...   \n",
       "8339  Dark, rich mountain blueberry and blackberry form the core of this classically delicious Napa Valley wine from an es...   \n",
       "5666  A beautifully dense, ripe wine, its intense acidity balanced by an opulent structure and gorgeous fruits. The textur...   \n",
       "3686  From one of the top estates in Cahors, this complex, dense wine is both structured and packed with great fruit. At t...   \n",
       "9552  Aged for a year in new wood barrels, this powerful, concentrated wine shows both richness and considerable aging pot...   \n",
       "7167  This wine is opulent and rich without losing sight of the freshness of the vintage. Layers of new wood (100%) are bl...   \n",
       "2305  Power and elegance come together in this beautifully proportioned, flavorful and pure-tasting wine. It has depth, co...   \n",
       "5380  A rare reserve-level Cabernet only made once before, this 100% varietal wine hails from esteemed Kiona and Ciel du C...   \n",
       "3307  One of Italy's most acclaimed Merlots, this concentrated wine opens with scents of black currants, cedar, sage and e...   \n",
       "918   Made from 100% Corvina, this shows the great potential of this native grape. It boasts rich blackberry, plum and lic...   \n",
       "2245  A blend of 78% Cabernet Sauvignon, 12% Petit Verdot, 5% Merlot and 5% Malbec, this is a tight, focused selection, wi...   \n",
       "2074  Great vineyards, great winery, great vintage: There's lots to like about this big, bold, fruity wine that manages to...   \n",
       "2727  Enticing scents of iris, violet, menthol and exotic spice emerge in the glass. Elegant and fresh, the polished, deli...   \n",
       "5501  Trefethen has been on a roll the last few years, producing some of Napa's most spectacular Cabernets. This bottling,...   \n",
       "\n",
       "      points  \n",
       "4661      94  \n",
       "9681      94  \n",
       "8339      93  \n",
       "5666      97  \n",
       "3686      94  \n",
       "9552      95  \n",
       "7167      95  \n",
       "2305      94  \n",
       "5380      93  \n",
       "3307      94  \n",
       "918       94  \n",
       "2245      91  \n",
       "2074      93  \n",
       "2727      94  \n",
       "5501      95  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_prediction.sort_values('High', ascending=False)[['description','points']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>Colorful and pretty to look at, but a little sweet. The nose has a sweet, maple syrup element along with dry berry f...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>Whole-cluster pressed, with 20% Marsanne in the blend, this displays fresh fruit flavors of apple and pear, with a b...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>Mild citrus aromas come with green notes. This is a medium-level Sauvignon Blanc without a lot of acidic snap. Melon...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Earthy, leafy red-fruit aromas are a bit rustic and burnt-smelling. This solid, chunky Pinot has spicy oak leading s...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9226</th>\n",
       "      <td>The light apple and mild citrus aromas are nice. It feels fresh and medium in intensity, with notes of peach, apple,...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>Earthy, meaty and leathery, with an herbal quality to the bouquet. The palate is chunky and soupy, with stewed berry...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>Sweet and mild aromas are highlighted by a touch of fresh prune. The mouthfeel is buttery, with plenty of toffee/cof...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Saucy tomato and herbal berry aromas are a bit green. This feels creamy and thick, but also bumpy. Oaky, herbal blac...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8887</th>\n",
       "      <td>Sure it's a bit simple and fruity—the flavors run toward berries and citrus—but it's also cleanly made, with a sligh...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>Gritty, waxy aromas of pithy citrus and vanilla feed into a fleshy palate with bracing acidity. Light, mild flavors ...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>Honeydew melon, just-sliced Gala apple and wet-cement aromas show on the nose of this bottling that starts to take o...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6901</th>\n",
       "      <td>Tart and angular on the nose, with sharp red berry and plum aromas. Crisp and acidic, with sweet-and-sour flavors in...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>Clean and fresh on the nose and palate with hints of fresh gooseberry, apple and red plum, Waters Crest's rosé could...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>A rather neutral nose leads to a simple, dry, fresh palate. There is a little citrus and green pear flavor. This is ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>Light scents of lime, white melon rind, green gooseberry and fresh-cut grass dance on the nose of this dainty white,...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  description  \\\n",
       "5132  Colorful and pretty to look at, but a little sweet. The nose has a sweet, maple syrup element along with dry berry f...   \n",
       "8134  Whole-cluster pressed, with 20% Marsanne in the blend, this displays fresh fruit flavors of apple and pear, with a b...   \n",
       "4508  Mild citrus aromas come with green notes. This is a medium-level Sauvignon Blanc without a lot of acidic snap. Melon...   \n",
       "1744  Earthy, leafy red-fruit aromas are a bit rustic and burnt-smelling. This solid, chunky Pinot has spicy oak leading s...   \n",
       "9226  The light apple and mild citrus aromas are nice. It feels fresh and medium in intensity, with notes of peach, apple,...   \n",
       "6860  Earthy, meaty and leathery, with an herbal quality to the bouquet. The palate is chunky and soupy, with stewed berry...   \n",
       "3220  Sweet and mild aromas are highlighted by a touch of fresh prune. The mouthfeel is buttery, with plenty of toffee/cof...   \n",
       "169   Saucy tomato and herbal berry aromas are a bit green. This feels creamy and thick, but also bumpy. Oaky, herbal blac...   \n",
       "8887  Sure it's a bit simple and fruity—the flavors run toward berries and citrus—but it's also cleanly made, with a sligh...   \n",
       "2435  Gritty, waxy aromas of pithy citrus and vanilla feed into a fleshy palate with bracing acidity. Light, mild flavors ...   \n",
       "9308  Honeydew melon, just-sliced Gala apple and wet-cement aromas show on the nose of this bottling that starts to take o...   \n",
       "6901  Tart and angular on the nose, with sharp red berry and plum aromas. Crisp and acidic, with sweet-and-sour flavors in...   \n",
       "4410  Clean and fresh on the nose and palate with hints of fresh gooseberry, apple and red plum, Waters Crest's rosé could...   \n",
       "3058  A rather neutral nose leads to a simple, dry, fresh palate. There is a little citrus and green pear flavor. This is ...   \n",
       "4115  Light scents of lime, white melon rind, green gooseberry and fresh-cut grass dance on the nose of this dainty white,...   \n",
       "\n",
       "      points  \n",
       "5132      86  \n",
       "8134      86  \n",
       "4508      85  \n",
       "1744      86  \n",
       "9226      87  \n",
       "6860      87  \n",
       "3220      87  \n",
       "169       84  \n",
       "8887      84  \n",
       "2435      86  \n",
       "9308      86  \n",
       "6901      84  \n",
       "4410      84  \n",
       "3058      87  \n",
       "4115      84  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df_prediction.sort_values('Low', ascending=False)[['description','points']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Exercise 2\n",
    "\n",
    " Which **post-1989** speech had the highest likelihood of being delivered during an earlier period?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What about overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split) will allow us to set aside a random subset of texts in our corpus to test the fit of our model. We can indicate the proportion of the total body of texts we'd like to set aside for testing the model using the `test_size` parameter. In the following example, we'll set aside 20% of the the wine reviews for testing by setting `test_size` to 0.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(wine_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split up our data for training and testing, we can set the parameters of our vectorizer, then `fit` the vectorizer to our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase   = True,\n",
    "                             ngram_range = (1,2),\n",
    "                             stop_words  = 'english',\n",
    "                             min_df      = .01,\n",
    "                             max_features = None)\n",
    "\n",
    "vectorizer.fit(train['description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `transform` method to return a document-term metrix for our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the MultinomialNB model from we imported earlier in the chapter, we can `fit` the matrix we've generated for descriptions of the wine reviews in the training data to the `rating` dummy variable indicating whether a wine received a high or low rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(X_train, train['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualizations provided through scikitlearn's `classification_report`, `confusion_matrix`, and `accuracy_score` will come in handy as we compare the performance of our model when applied to our training data versus our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train['rating'],\n",
    "                     nb_classifier.predict(X_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can make this comparison, though, we'll have to `transform` our the raw documents in our test data into a document-term matrix. We'll also need to define our prediction model using the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "test_wf         = vectorizer.transform(test['description'])\n",
    "test_prediction = nb_classifier.predict(test_wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test['rating'], test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             ngram_range = (1,3),\n",
    "                             stop_words = 'english',\n",
    "                             max_df = .60,\n",
    "                             min_df = 5,\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train['description'])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "X_train = vectorizer.transform(train['description'])\n",
    "nb_classifier.fit(X_train, train['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.841875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train['rating'],\n",
    "                     nb_classifier.predict(X_train)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(test['rating'],\n",
    "                     nb_classifier.predict(vectorizer.transform(test['description']))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Exercise 3\n",
    "\n",
    "What happens to your model if you change some of the parameters for your vectorizer? Be sure to spit the data between train and test!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What about a different model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to MultinomialNB, we can also import a [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression) model from scikitlearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ln_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the parameters of our vectorizer, and fit the vectorizer to the training data in our wine dataframe. This will produce a total of 463 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             ngram_range = (1,2),\n",
    "                             stop_words = 'english',\n",
    "                             min_df = .01,\n",
    "                             max_features = None)\n",
    "\n",
    "vectorizer.fit(train['description'])\n",
    "\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "ln_classifier.fit(vectorizer.transform(train['description']), train['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the accuracy scores returned for the training and testing data when applying a logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904125\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(train['rating'],\n",
    "                     ln_classifier.predict(vectorizer.transform(train['description']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8545\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test['rating'],\n",
    "                     ln_classifier.predict(vectorizer.transform(test['description']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the `heatmap` function from before to get a quick feel for how our model holds up when fit to our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x126bd5850>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVKUlEQVR4nO3dfZSXdZ3/8ed7BkHQUIgfSAwqFWaQuqbHY9qNrougZri70VJq1I9fJJrZrv02sFqrXTb2dLPZWtgkImbejOZP2U4iN91YViKKyd2aeBOOjJAiyq4mMHx+f8wlfZEZGIaZ+X7m4vmYc53v9/u57j7XOePLD+/rc30nUkpIkvJSU+0OSJJ2ZThLUoYMZ0nKkOEsSRkynCUpQ726+gTnz7/Y6SDaxawzZlS7C8pQ/wMGxL4eI8bUtTtz0sLGfT5fV3HkLEkZ6vKRsyR1q8h2MLxXDGdJ5VJrOEtSfsqRzYazpJKxrCFJGSrJNAfDWVK5OHKWpAyVI5sNZ0kl42wNScpQScoaJSmdS1Ih9mLZ06EirouIDRGxoqJtYEQsjIjHitcBFeumR8SaiHg0IsZWtJ8QEcuLdd+O2PP/QQxnSeVSE+1f9ux6YNzr2qYBi1NKI4HFxWciYhQwERhd7PPdiKgt9pkFTAFGFsvrj7nrZbSnd5LUY3TiyDmldC+w8XXN44G5xfu5wHkV7beklF5NKT0JrAFOioihQP+U0m9Sy98FvKFinzZZc5ZULrXtH3NGxBRaRrSvqU8p1e9htyEppSaAlFJTRAwu2ocBv63YrrFo21q8f337bhnOksplL+4HFkG8pzDelzOn3bTvlmUNSeUS0f6lY9YXpQqK1w1FeyMwvGK7OmBd0V7XSvtuGc6SyqUTa85tmAdMKt5PAu6qaJ8YEX0iYgQtN/6WFCWQzRFxcjFL46MV+7TJsoakcmnfLIx2iYibgdOAQRHRCFwJzAQaImIysBaYAJBSWhkRDcAqYBtwSUqpuTjUVFpmfvQF7i6W3TKcJZVLJz6DklL6cBurzmhj+xnALn+DLaW0FHjH3pzbcJZULj6+LUkZKsnj24azpHIpRzYbzpJKxpGzJGWoJBOEDWdJ5dKJU+mqyXCWVC6GsyRlyJqzJGWoHNlsOEsql3b8kZEewXCWVCqGsyRlqNYbgpKUH0fOkpQhw1mSMmQ4S1KGSpLNhrOkcnHkLEkZqolyfPOR4SypVBw5S1KGSpLNhrOkcqkpSTobzpJKxbKGJGWoxse3JSk/jpwlKUOGsyRlyHCWpAwZzpKUoZJks+EsqVxqanx8W5Ky40MokpShkmSz4dyZ+vXqyyfecT51B7+JBNSv+AHHDhrF6XWnsnnLZgBu/f08fvfcSg4+4CAu+4tP8OZDDufeZ37L3NUN1e28usxXvvAv/Ore+xgwcAC33nnTjvZbf9hAw823U1tby7vfewqfvvxS7v7xfH4w54c7tlnz+zX84La5vO3oo6rR9R7JG4LaxYVvn8DvnlvFVQ9fS23U0qe2N8cOGsXdT/2Unzy1aKdtt27fym2P/SfD3/Am6g4eWqUeqzu8/7xz+NBHPsiVV3xlR9vSJQ/yi5/dy8133Ejv3r3Z+PxGAM56/zjOev84oCWYL//0PxrMeynYT8I5Io4GxgPDgASsA+allFZ3cd96lL61B3L0gLfyveU3ANCcmnl52yttbv9q8xZ+v+lxDjvof3VXF1Ul7zzxeNY9s26nth/degeTJn+U3r17AzDwjQN32e+enyxk7FljuqWPZVKWkfNub2tGxOeAW4AAlgAPFO9vjohpXd+9nmNwv0Fs3vLffPKYC5lxynT+z+jz6VPb8h/emUe8j6+e+nk+8Y4L6Nerb5V7qhz84am1PPzg7/jYh/83Uz42lZXLV+2yzcL5izjz7DOr0LueraYm2r3kbE8j58nA6JTS1srGiPgmsBKY2dpOETEFmAJw0qXv461nj+qEruatJmo4sv9w5q5u4PEXn+LCoydw7ogzWbD2F/y/NT8B4IMjz+X8o/+W76+4scq9VbU1Nzez+aWXmHPTbFatWMUVn/08d86/Y8eob8UjKziw74G8deRbqtzTnme/GDkD24E3tdI+tFjXqpRSfUrpxJTSiftDMANs/NMmNr66icdffAqAJesf4sj+h/PSls2k4udnjb/iLYccWdV+Kg+Dhwzm9L86jYhg9DGjiahh0wubdqxfcPciSxodFBHtXnK2p3D+DLA4Iu6OiPpimQ8sBi7r+u71HC9ueYnnX3mBoQcNBmD0G4/mmf9p4tA+/Xdsc+Lgv6Dxv9e1dQjtR077y/fywJIHgZYSx9atWzl0wKEAbN++ncULFjPGcO6QzgzniPj7iFgZESsi4uaIODAiBkbEwoh4rHgdULH99IhYExGPRsTYfbmO3ZY1UkrzI+Io4CRabggG0Ag8kFJq3pcTl9ENqxu4+NiP06umFxtefo7vLb+BSW//EEf0ryMBf3zlea5b+eepVN963z/Tt/ZAetXUcuKQ45j5wH/wzP88W70LUJf4/P/9Ig8+8BCbNm3inDPOZcrFn+ADf3MuX/nCv/B3532EAw7oxZf+9Z92hMWypcsYPGQwdcOHVbnnPVNnDYgjYhjwaWBUSumViGgAJgKjgMUppZnFvbdpwOciYlSxfjQtFYdFEXFUR7MyUkqdciFtOX/+xV17AvVIs86YUe0uKEP9Dxiwz9H69qvObnfmrL7sJ22erwjn3wLHAS8BdwLfBv4DOC2l1BQRQ4Gfp5TeFhHTAVJKXy32vwf4UkrpNx25jnI8hC5Jhb0pa0TElIhYWrFMee04KaVngK8Da4Em4MWU0gJgSEqpqdimCRhc7DIMeLqiK41FW4f4EIqkUtmbskZKqR6ob/04MYCWZzxGAJuA2yLigt2durVTtL83OzOcJZVKJ87C+CvgyZTSH4vj3gGcAqyPiKEVZY0NxfaNwPCK/etoeWivQyxrSCqVTpytsRY4OSL6RcvGZwCrgXnApGKbScBdxft5wMSI6BMRI4CRtDy81yGOnCWVSmeNnFNK90fE7cBDwDZgGS0lkIOBhoiYTEuATyi2X1nM6FhVbH/JvsxqM5wllUpnPpadUroSuPJ1za/SMopubfsZQKdMRTKcJZVL5k/+tZfhLKlUcn8su70MZ0mlUpJsNpwllYsjZ0nKkOEsSRnK/Uv028twllQqjpwlKUOGsyRlyHCWpAwZzpKUIW8ISlKGHDlLUoYMZ0nKUEmy2XCWVC6OnCUpR4azJOWn1tkakpQfyxqSlKEaw1mS8uPIWZIyVFPtDnQSw1lSqdTWlCOeDWdJpWLNWZIyZM1ZkjJUjqKG4SypZCxrSFKGLGtIUoZqDWdJyo9lDUnKkOEsSRmy5ixJGXLkLEkZKkc0G86SSqaX360hSfmx5ixJGbLmLEkZKkc0G86SSqYsI+dyVM4lqVBbU9PuZU8i4tCIuD0i/isiVkfEuyJiYEQsjIjHitcBFdtPj4g1EfFoRIzdl+swnCWVSs1eLO1wFTA/pXQ0cBywGpgGLE4pjQQWF5+JiFHARGA0MA74bkTU7st1SFJpRES7lz0cpz/wXmA2QEppS0ppEzAemFtsNhc4r3g/HrglpfRqSulJYA1wUkevw3CWVCo1Ee1eImJKRCytWKZUHOrNwB+BORGxLCKujYiDgCEppSaA4nVwsf0w4OmK/RuLtg7xhqCkUtmbG4IppXqgvo3VvYB3ApemlO6PiKsoShhtaO3Eqd2daeXkXWr2mK939SnUA/Udd1S1u6AMpYWN+3yMTnwIpRFoTCndX3y+nZZwXh8RQ1NKTRExFNhQsf3wiv3rgHUdPbllDUmlUhs17V52J6X0LPB0RLytaDoDWAXMAyYVbZOAu4r384CJEdEnIkYAI4ElHb0OyxqSSqWT5zlfCvwwInoDTwAfp2VQ2xARk4G1wASAlNLKiGigJcC3AZeklJo7emLDWVKpRCc+I5hSehg4sZVVZ7Sx/QxgRmec23CWVCp+8ZEkZagsj28bzpJKJUoyz8FwllQq7fnOjJ7AcJZUKp15Q7CaDGdJpWLNWZIy5GwNScpQjTcEJSk/Nd4QlKT81HhDUJLyY81ZkjLkbA1JypDznCUpQzV7+J7mnsJwllQqhrMkZciasyRlyJqzJGXIkbMkZSisOUtSfixrSFKG/LJ9ScqQ360hSRnyuzUkKUPeEJSkDFnWkKQM+fi2JGXImrMkZciyhiRlyBuCkpQhnxCUpAxZc5akDDlbQ5Iy5A1BScqQZQ1JylBgWUOSsuPIWZIyVFuSG4LluApJKsRe/LTreBG1EbEsIn5cfB4YEQsj4rHidUDFttMjYk1EPBoRY/flOgxnSaUSEe1e2ukyYHXF52nA4pTSSGBx8ZmIGAVMBEYD44DvRkRtR6/DcJZUKkFNu5c9HiuiDjgHuLaieTwwt3g/Fzivov2WlNKrKaUngTXASR29DsNZUql08sj5W8A/Atsr2oaklJoAitfBRfsw4OmK7RqLtg4xnCWVSvvHzUFETImIpRXLlNeOExHvBzaklB5s56lbS/vU0etwtoakUtmbx7dTSvVAfRurTwU+EBFnAwcC/SPiRmB9RAxNKTVFxFBgQ7F9IzC8Yv86YN3e9v81jpwllUpnlTVSStNTSnUppSNpudH305TSBcA8YFKx2STgruL9PGBiRPSJiBHASGBJR6/DkbOkUumGJwRnAg0RMRlYC0wASCmtjIgGYBWwDbgkpdTc0ZMYzpJKpaYLnhBMKf0c+Hnx/nngjDa2mwHM6IxzWtboRP/0+S9x2rv/kr/5wAd3tH3za//O+HP+mg+e9yE+c+k/8NJLm3fap2ldEyefcApzr7uhu7urLjL78q+zvuFhltcv2tE24A2HsmDmTfz++l+yYOZNHHrwIQAcMaSOl3+8hmXX3MOya+5h1mVf3bHPxNPH80j9In73vYXc/a838sb+A3Y5l3bV2Q+hVIvh3InG//W5zKr/zk5tJ59yMj+66zZuv7OBI448gtnfv26n9V/7t6/z7vec2p3dVBe7fsFtjLvigp3apv3dJSxedh9Hfew9LF52H9MmXrJj3ePrnuL4i8Zy/EVjmXrVdABqa2q5auqXOf2zEzjuk2N45InVfGr8x7v1OnqqLngIpSoM5050wokn0P+QQ3ZqO+XUd9GrV0v16NjjjmHDs+t3rPvpop9RV1fHW976lm7tp7rWL5ffz8bNm3ZqG3/KmcxdeBsAcxfexnmn7P7J3tfC46AD+wHQ/6CDWff8+t3uoxY1UdPuJWd5965k7rzjLk4tRskvv/wKc2bP4aKLP1nlXqk7DBkwiGc3tsy4enbjBgYf+sYd60YcdjgPzZrPz79xO+9+R8sDZduatzH121ewvH4R6255kFGHj2T2/Jur0veepmYvfnLW4d5FRJv/xqqc2P36f8bvr75/zbXU1tZyzrlnAzDr6llc8NEL6HdQvyr3TNXUtHEDh59/Eu+cOo5/uObL3DT9at7Q72B61fZi6rkXcvzUcbxp4gk88uR/MX3ip6rd3R6hLGWNfZmt8WVgTmsrKid2/6n55Q4/IVMW8+6cx72/uJf667634xdi+SMrWLRgEd/6xrfYvHkzETX07tObD58/scq9VVdY/8JzHDZwMM9u3MBhAwezYdPzAGzZuoWNW7cA8NBjy3m86Q8cVffmHTernmj6AwANv/jPnerUalvuN/raa7fhHBGPtLUKGNL53Smf+355H3OuvZ7ZN1xL3759d7Rff+Of/0Ux6+pr6Nevn8FcYvN+s5BJYybwb7d+h0ljJnDXrxcAMOiQgWzcvInt27cz4rDDGTlsBE80reXA3n0YdfhIBh0ykOde3MiYd76H1Wsfq/JV9Ay5j4jba08j5yHAWOCF17UH8Osu6VEP9rnPTmPpkgfZtGkTY04fy9RPXcR19XPYsnULF02eCsAxxx3DF7/0hSr3VF3ppiuu5rRj38WgQwby9E0PcOUN32DmLVfT8MVrmHzWRNZueIYJ/3wRAO895mS+MulytjU307y9mYuumsYLxc3EL9/479z7zR+xdds2/rC+kY997e+reVk9Ru615PaKlNquOkTEbGBOSulXray7KaX0kT2dwLKGWtN33FHV7oIylBY27vOwd+lzv2535pw46JRsh9m7HTmnlCbvZt0eg1mSutt+UXOWpJ5mf6k5S1KP4shZkjJkOEtShnJ/LLu9DGdJpeLIWZIy5A1BScqQI2dJypAjZ0nKkCNnScqQszUkKUOOnCUpQ4azJGXIG4KSlCXDWZKy4w1BScqQNWdJypA1Z0nKkCNnScqQ4SxJGbKsIUkZcraGJGXIsoYkZclwlqTslCOaDWdJJeMNQUnKkuEsSdnxhqAkZagsZY1yTAiUpE4WEcMj4mcRsToiVkbEZUX7wIhYGBGPFa8DKvaZHhFrIuLRiBi7L+c3nCWVSuzFzx5sAy5PKb0dOBm4JCJGAdOAxSmlkcDi4jPFuonAaGAc8N2IqO3odRjOkkqls8I5pdSUUnqoeL8ZWA0MA8YDc4vN5gLnFe/HA7eklF5NKT0JrAFO6uh1GM6SSiUi9maZEhFLK5YpbRzzSOB44H5gSEqpCVoCHBhcbDYMeLpit8airUO8IShpv5VSqgfqd7dNRBwM/Aj4TErppd3ccGxtRepo3xw5SyqVTqw5ExEH0BLMP0wp3VE0r4+IocX6ocCGor0RGF6xex2wrqPXYThLKpnYi2U3R2kZIs8GVqeUvlmxah4wqXg/Cbiron1iRPSJiBHASGBJR6/CsoakUunEWc6nAhcCyyPi4aLtCmAm0BARk4G1wASAlNLKiGgAVtEy0+OSlFJzR08eKXW4JNIuf2p+uWtPoB6p77ijqt0FZSgtbNznbN205bl2Z86hvQdl+8SKI2dJpeLj25KUJcNZkrLjd2tIkrqMI2dJpWLNWZKyZDhLUnZqSlJzNpwllYzhLEnZKUc0G86SSqcc8Ww4SyqVssxzNpwllUpZptJ1+Rcf6c8iYkrx5d7SDv5eqDU+Idi9Wv0TONrv+XuhXRjOkpQhw1mSMmQ4dy/rimqNvxfahTcEJSlDjpwlKUOGsyRlyHDuJhExLiIejYg1ETGt2v1R9UXEdRGxISJWVLsvyo/h3A0iohb4DnAWMAr4cESMqm6vlIHrgXHV7oTyZDh3j5OANSmlJ1JKW4BbgPFV7pOqLKV0L7Cx2v1Qngzn7jEMeLric2PRJkmtMpy7R2vfxOIcRkltMpy7RyMwvOJzHbCuSn2R1AMYzt3jAWBkRIyIiN7ARGBelfskKWOGczdIKW0DPgXcA6wGGlJKK6vbK1VbRNwM/AZ4W0Q0RsTkavdJ+fDxbUnKkCNnScqQ4SxJGTKcJSlDhrMkZchwlqQMGc6SlCHDWZIy9P8BqI0b3NxcyaAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction = ln_classifier.predict(vectorizer.transform(test['description']))\n",
    "\n",
    "cm = confusion_matrix(test['rating'], test_prediction)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Exercise 4\n",
    "\n",
    "What is the out sample accuracy of a logistic regression model on your data?\n",
    "\n",
    "`from sklearn.linear_model import LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What about a different model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/knn1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf_vector  = TfidfVectorizer(lowercase  =  True,\n",
    "                             ngram_range = (1,2),\n",
    "                             stop_words  = 'english',\n",
    "                             max_df      = .60,\n",
    "                             min_df      = .05,\n",
    "                             max_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(wine_df, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.6, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vector.fit(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "review_tf = tf_vector.transform(train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_classifier.fit(review_tf, train['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_prediction = knn_classifier.predict(review_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431748766543974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(train['rating'], knn_prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.84      0.74      0.79      9987\n",
      "         Low       0.85      0.91      0.88     15551\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25538\n",
      "   macro avg       0.84      0.83      0.83     25538\n",
      "weighted avg       0.84      0.84      0.84     25538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train['rating'], knn_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1270d0470>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(train['rating'], knn_prediction)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Exercise 5\n",
    "\n",
    "What does a k-nearest neigbhor for your speech dataset look like? (Don't forget to shrink your dataframe). How does the accuracy compare?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/knn2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But what's the best fitting model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# old model: knn_classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "parameters = {'n_neighbors' : [2,3, 7],\n",
    "              'weights'      : ['distance', 'uniform']}\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(KNeighborsClassifier(), \n",
    "                    parameters, \n",
    "                    cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/cv.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But what's the best fitting model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "                     ('vectorizer' , CountVectorizer()),\n",
    "                     ('classifier' , LogisticRegression())\n",
    "                    ])\n",
    "\n",
    "parameters = {'vectorizer__max_features' : [300, 500, 700],\n",
    "               }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 5,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   52.7s finished\n",
      "/Users/nealcaren/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=No...\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'vectorizer__max_features': [300, 500, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(wine_df['description'],\n",
    "                wine_df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8988934310685086"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=700, min_df=1, ngram_range=(1, 1),\n",
       "                                 preprocessor=None, stop_words=None,\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=700, min_df=1, ngram_range=(1, 1),\n",
       "                                 preprocessor=None, stop_words=None,\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification Exercise 6\n",
    "\n",
    "The \"data\" folder contains board games descriptions scraped from BoardGameGeeks.com. Analyze the relationship between the words in the `description` and whether or not reviewers thought it was a `quality_game`. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
